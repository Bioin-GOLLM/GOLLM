{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMC2811213\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import time\n",
    "import os\n",
    "\n",
    "def pmid_to_pmcid(pmid):\n",
    "    \"\"\"\n",
    "    Convert a PMID to PMCID using NCBI's idconv utility.\n",
    "    Returns None if conversion fails.\n",
    "    \"\"\"\n",
    "    url = f\"https://www.ncbi.nlm.nih.gov/pmc/utils/idconv/v1.0/?ids={pmid}&format=xml\"\n",
    "    resp = requests.get(url)\n",
    "    if resp.status_code != 200:\n",
    "        return None\n",
    "\n",
    "    root = ET.fromstring(resp.text)\n",
    "    # The API returns a record element with attributes:\n",
    "    record = root.find(\"record\")\n",
    "    if record is not None:\n",
    "        return record.attrib.get(\"pmcid\")\n",
    "    return None\n",
    "\n",
    "def pmcid_to_pmid(pmcid):\n",
    "    \"\"\"\n",
    "    Convert a PMCID to PMID using NCBI's idconv utility.\n",
    "    Returns None if conversion fails.\n",
    "    \"\"\"\n",
    "    url = f\"https://www.ncbi.nlm.nih.gov/pmc/utils/idconv/v1.0/?ids={pmcid}&format=xml\"\n",
    "    resp = requests.get(url)\n",
    "    if resp.status_code != 200:\n",
    "        return None\n",
    "\n",
    "    root = ET.fromstring(resp.text)\n",
    "    # The API returns a record element with attributes:\n",
    "    record = root.find(\"record\")\n",
    "    if record is not None:\n",
    "        return record.attrib.get(\"pmid\")\n",
    "    return None\n",
    "\n",
    "print(pmid_to_pmcid(\"28813417\"))\n",
    "# list_of_pmid = []\n",
    "# count = 0\n",
    "# folder_path = \"./output/Annotated\"\n",
    "# for filename in os.listdir(folder_path):\n",
    "#     name, extension = os.path.splitext(filename)\n",
    "#     time.sleep(0.2)\n",
    "#     result = pmcid_to_pmid(name)\n",
    "#     if result in [\"19419240\", \"29167800\", \"30729664\", \"35484106\"]:\n",
    "#         list_of_pmid.append(name)\n",
    "#     count+= 1\n",
    "\n",
    "# print(count)\n",
    "# print(pmcid_to_pmid(\"PMC2669177\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_pmid.sort()\n",
    "for i in range(len(list_of_pmid)):\n",
    "    if list_of_pmid[i] == None:\n",
    "        print(\"None\")\n",
    "    else:\n",
    "        print(list_of_pmid[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to your Excel file\n",
    "file_path = r'C:\\Users\\aivan\\OneDrive\\Documents\\book1.xlsx'\n",
    "\n",
    "# Load Excel file, skipping the first row for each sheet\n",
    "xls = pd.ExcelFile(file_path)\n",
    "sheets = xls.sheet_names\n",
    "\n",
    "# if the names of the sheets are PMC9050729, PMC6102311, skip them\n",
    "sheets = [sheet for sheet in sheets if sheet not in [\"PMC9050729\", \"PMC6102311\"]]\n",
    "\n",
    "# Read each sheet into a DataFrame, skip the first row in each sheet\n",
    "dfs = [pd.read_excel(xls, sheet_name=sheet, skiprows=1) for sheet in sheets]\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "merged_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Save the merged DataFrame to a new Excel file\n",
    "merged_df.to_excel('C:/Users/aivan/OneDrive/Documents/merged_output.xlsx', index=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BIOIN311C1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
