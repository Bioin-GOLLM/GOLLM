{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AfSrrXBI8oi",
        "outputId": "3b20254b-e106-40b9-8f89-a0aa03fba087"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWSHSonXlTeG"
      },
      "outputs": [],
      "source": [
        "# packages\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuXWNP8jcVkz"
      },
      "source": [
        "# 1. Pubtator API (TODO-Partially done)\n",
        "- using the input folder, check if the file(s) have been pre-annotated by checking if the following APIs return something\n",
        "```\n",
        "https://www.ncbi.nlm.nih.gov/research/pubtator3-api/publications/export/biocxml?pmids={id}\n",
        "or\n",
        "https://www.ncbi.nlm.nih.gov/research/pubtator3-api/publications/pmc_export/biocxml?pmcids=PMC{id}\n",
        "```\n",
        "  - if annotated, retrieve it and put it in the output folder\n",
        "  - if not, use the [example code](https://www.ncbi.nlm.nih.gov/CBBresearch/Lu/Demo/tmTools/download/ExampleCode.Python.zip) they provide to send it to the server to be annotated (Done)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sl2nmCPFsQq"
      },
      "source": [
        "Using colab:\n",
        "\n",
        "```\n",
        "mkdir input\n",
        "```\n",
        "\n",
        "to make a input folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edkmlyhFFifa",
        "outputId": "304ffdaa-8b04-4d0b-de90-f3caa4e5f27f"
      },
      "outputs": [],
      "source": [
        "!bash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQIruerqbU4Q",
        "outputId": "da090b16-ca20-4798-a26d-7bce4bc4090a"
      },
      "outputs": [],
      "source": [
        "# SubmitText_request.py\n",
        "!pip install unidecode\n",
        "\n",
        "import requests\n",
        "import os\n",
        "import sys\n",
        "from unidecode import unidecode\n",
        "import unicodedata\n",
        "import re\n",
        "\n",
        "def submit_text_request(input_folder, bioconcept, output_file_session_number):\n",
        "    pattern = r'[^0-9a-zA-Z\\!\\@\\#\\$\\%\\^\\&\\*\\(\\)\\_\\+\\{\\}\\|\\:\\\"\\<\\>\\?\\-\\=\\[\\]\\\\;\\'\\,\\.\\/ \\t\\n\\r]'\n",
        "    unicode_to_regular = {}\n",
        "    with open('lib/unicode.txt', 'r', encoding='utf-8') as input_file:\n",
        "        for line in input_file:\n",
        "            line = line.strip()\n",
        "            parts = line.split(\"\\t\")\n",
        "            if len(parts) == 2:\n",
        "                uni, reg = parts\n",
        "                if reg == '-whitespace-':\n",
        "                    unicode_to_regular[uni] = ' '\n",
        "                else:\n",
        "                    unicode_to_regular[uni] = reg\n",
        "\n",
        "    with open(output_file_session_number, 'w', encoding='utf-8') as output_file:\n",
        "        for filename in os.listdir(input_folder):\n",
        "            if filename.startswith('.'):\n",
        "                continue  # Skip hidden files\n",
        "            text_str = ''\n",
        "            with open(os.path.join(input_folder, filename), 'r', encoding='utf-8') as file_input:\n",
        "                for line in file_input:\n",
        "                    normalized_line = unicodedata.normalize('NFC', line)\n",
        "                    for uni, reg in unicode_to_regular.items():\n",
        "                        normalized_line = normalized_line.replace(uni, reg)\n",
        "                    normalized_line = unidecode(normalized_line)  # Assuming unidecode does similar work to Perl's version\n",
        "                    text_str += normalized_line\n",
        "            text_str = re.sub(pattern, ' ', text_str)\n",
        "            url = \"https://www.ncbi.nlm.nih.gov/CBBresearch/Lu/Demo/RESTful/request.cgi\"\n",
        "            response = requests.post(url, data={'text': text_str, 'bioconcept': bioconcept})\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                session_number = response.json().get('id', '')\n",
        "                print(f\"Thanks for your submission. The session number is: {session_number}\")\n",
        "                output_file.write(f\"{session_number}\\t{filename}\\n\")\n",
        "            else:\n",
        "                print(f\"Error: HTTP {response.status_code} for {filename}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KccYUHYJcEfG"
      },
      "outputs": [],
      "source": [
        "# SubmitText_retreive.py\n",
        "import requests\n",
        "import os\n",
        "import sys\n",
        "\n",
        "def submit_text_retrieve(input_folder, inputfile_session_number, output_folder):\n",
        "    # Ensure output directory exists\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    sn_hash = {}\n",
        "    with open(inputfile_session_number, 'r') as input_file:\n",
        "        for line in input_file:\n",
        "            line = line.strip()\n",
        "            if line:\n",
        "                session_number, input_filename = line.split(\"\\t\")\n",
        "                sn_hash[session_number] = input_filename\n",
        "\n",
        "    base_url = \"https://www.ncbi.nlm.nih.gov/CBBresearch/Lu/Demo/RESTful/retrieve.cgi\"\n",
        "\n",
        "    for session_number, input_filename in sn_hash.items():\n",
        "        output_file_path = os.path.join(output_folder, input_filename)\n",
        "        if os.path.exists(output_file_path):\n",
        "            print(f\"{output_file_path} - finished\")\n",
        "            continue\n",
        "\n",
        "        retrieve_url = f\"{base_url}?id={session_number}\"\n",
        "        response = requests.get(retrieve_url)\n",
        "        if response.status_code == 200:\n",
        "            with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "                output_file.write(response.text)\n",
        "            print(f\"{session_number} : Result is retrieved.\")\n",
        "        else:\n",
        "            print(f\"{session_number} : Error retrieving results - {response.status_code}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_lpKfmLcaQ-",
        "outputId": "756447fc-8c07-43f6-f6a6-4db2fcb68e62"
      },
      "outputs": [],
      "source": [
        "input_folder = \"input\"       # pull xml,json, or pubtator formatted files here to be annotated\n",
        "bioconcept = \"Gene\"                                         # we only want the genes\n",
        "output_file_session_number = \"Session_Number.txt\"  # output file for session number which will be used to retrieve the results\n",
        "submit_text_request(input_folder, bioconcept, output_file_session_number)    # submit the text for annotation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02JFZ15QfHqt"
      },
      "source": [
        "## Running the code below takes time, so it might say error 400. Just rerun it a bit later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmQYNjmJdzwO",
        "outputId": "0284e0d6-cf18-4d40-85f9-b49dd3e7890a"
      },
      "outputs": [],
      "source": [
        "input_folder = \"input\"\n",
        "inputfile_session_number = \"Session_Number.txt\"\n",
        "output_folder = \"output\"\n",
        "submit_text_retrieve(input_folder, inputfile_session_number, output_folder)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duMZk-ubdK0K"
      },
      "source": [
        "# 2. Relevance (Done)\n",
        "- This can be integrated with Gene Chunking. We can just check if the paper has genes (i.e check if there is an item in the dictionary @ line 171)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-Gak1R_RF8Y"
      },
      "source": [
        "*3. Gene Chunking*\n",
        "=============\n",
        "Given a **preannotated** article (check input folder) analyze the **XML** file via `parse_xml_file(xml_file_path)` which returns a dictionary of \"Gene Class\" from that file  \n",
        "\n",
        "The Gene Class has the following information:\n",
        "- self.gene_id: the gene id (from the xml file)\n",
        "- self.occurences: A list of occurences of the gene in the text. Each occurence is **3-sentences long**.\n",
        "    - The second sentence contains the explicit mention of the gene.\n",
        "    - The first and third sentences are the context of the gene mention.\n",
        "- self.symbol: the gene symbol (from NCBI. Initialized to None)\n",
        "- self.organism: the organism of the gene (from NCBI. Initialized to None)\n",
        "- self.full_name: the full name of the gene (from NCBI. Initialized to None. Set to name_from_article if not found in NCBI)\n",
        "- self.also_known_as: a list of other names of the gene (from NCBI. Initialized to None. Set to name_from_article if not found in NCBI)\n",
        "- self.name_from_article: the name of the gene as found in the article\n",
        "\n",
        "Steps:\n",
        "1. define the class Gene\n",
        "2. Parse the xml file\n",
        "3. update the Gene class with the information from NCBI\n",
        "Now you have a dictionary of Gene classes.~\n",
        "\n",
        "TIPS:\n",
        "- control + F \"sentence_buffer\" to find where you can adjust the buffer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9sSOV2PXqOJ",
        "outputId": "6722699e-967f-4dee-c51c-fce74a88168e"
      },
      "outputs": [],
      "source": [
        "!pip install biopython\n",
        "import xml.etree.ElementTree as ET\n",
        "from Bio import Entrez\n",
        "import re\n",
        "import time\n",
        "\n",
        "class Gene:\n",
        "    def __init__(self, gene_id):\n",
        "        self.gene_id = gene_id\n",
        "        self.occurrences = []  # list to store snippet(s) where the gene was mentioned\n",
        "        self.symbol = None\n",
        "        self.organism = None\n",
        "        self.full_name = None\n",
        "        self.also_known_as = None\n",
        "        self.name_from_article = None\n",
        "        self.doc_id = None\n",
        "\n",
        "    def add_occurrence(self, snippet):\n",
        "        if snippet not in self.occurrences:  # Avoid duplicates\n",
        "            self.occurrences.append(snippet)\n",
        "\n",
        "    def set_name_from_article(self, name_from_article):\n",
        "        \"\"\"Sets the temporary name of the gene. This is the name according to the article\"\"\"\n",
        "        self.name_from_article = name_from_article\n",
        "\n",
        "    def get_name_from_article(self):\n",
        "        return self.name_from_article\n",
        "\n",
        "    def get_occurrences(self):\n",
        "        return self.occurrences\n",
        "\n",
        "    def get_also_known_as(self):\n",
        "        return self.also_known_as\n",
        "\n",
        "    def get_gene_id(self):\n",
        "        return self.gene_id\n",
        "    \n",
        "    def get_organsim(self):\n",
        "        return self.organism\n",
        "    \n",
        "    def get_doc_id(self):\n",
        "        return self.doc_id\n",
        "    \n",
        "    def set_doc_id(self, doc_id):\n",
        "        self.doc_id = doc_id\n",
        "\n",
        "    def update_info(self, symbol, organism, full_name, also_known_as):\n",
        "        self.symbol = symbol\n",
        "        self.organism = organism\n",
        "        self.full_name = full_name\n",
        "        self.also_known_as = also_known_as\n",
        "\n",
        "    def __repr__(self):\n",
        "        return (f\"Gene({self.gene_id})\\n\"\n",
        "                f\"  Symbol          : {self.symbol}\\n\"\n",
        "                f\"  Organism        : {self.organism}\\n\"\n",
        "                f\"  Full Name       : {self.full_name}\\n\"\n",
        "                f\"  Also Known As   : {self.also_known_as}\\n\"\n",
        "                f\"  In-text Name    : {self.name_from_article}\\n\"\n",
        "                f\"  Occurrences     : {self.occurrences}\\n\"\n",
        "                f\"  Document ID     : {self.doc_id}\")\n",
        "\n",
        "def parse_xml_file(xml_path):\n",
        "    \"\"\"Parses the XML file and returns a gene dictionary keyed by gene ID.\"\"\"\n",
        "    tree = ET.parse(xml_path)\n",
        "    root = tree.getroot()\n",
        "    gene_dict = {}\n",
        "\n",
        "    for document in root.findall('document'):\n",
        "        \n",
        "        # get the document ID (pmid or pmcid)\n",
        "        doc_id_elem = document.find('id')\n",
        "        if doc_id_elem is not None:\n",
        "            doc_id = doc_id_elem.text\n",
        "        else:\n",
        "            doc_id = None\n",
        "\n",
        "\n",
        "        # get the gene annotations in the document from the passages\n",
        "        for passage in document.findall('passage'):       \n",
        "            # Also check for 'article-id_pmc'\n",
        "            article_id_pmc_elem = passage.find(\"infon[@key='article-id_pmc']\")\n",
        "            if article_id_pmc_elem is not None:\n",
        "                pmc_value = article_id_pmc_elem.text.strip()\n",
        "                if not pmc_value.startswith(\"PMC\"):\n",
        "                    pmc_value = \"PMC\" + pmc_value\n",
        "                doc_id = pmc_value     \n",
        "            section_type_elem = passage.find(\"infon[@key='section_type']\")\n",
        "            if section_type_elem is not None and section_type_elem.text and section_type_elem.text.upper() in (\"METHODS\", \"FIG\", \"TABLE\"):\n",
        "                continue  # Skip passages under METHODS\n",
        "            # Get the full passage text.\n",
        "            passage_text_elem = passage.find(\"text\")\n",
        "            passage_text = passage_text_elem.text if passage_text_elem is not None else \"\"\n",
        "            # Determine the starting offset for this passage.\n",
        "            passage_offset_elem = passage.find(\"offset\")\n",
        "            passage_offset = int(passage_offset_elem.text) if passage_offset_elem is not None else 0\n",
        "            # Split the passage into sentences using regex.\n",
        "            sentences = re.split(r'(?<=[.!?])\\s+', passage_text)\n",
        "            # Compute start indices for each sentence within the passage text.\n",
        "            start_indices = []\n",
        "            current_index = passage_offset\n",
        "            for sentence in sentences:\n",
        "                start_indices.append(current_index)\n",
        "                current_index += len(sentence) + 1  # account for the delimiter space\n",
        "\n",
        "            # Dictionary to store annotations per gene in this passage.\n",
        "            # For each gene_id, we collect the sentence indices and a temporary in-text name.\n",
        "            gene_annotations = {}\n",
        "            for annotation in passage.findall('annotation'):\n",
        "                ann_type = annotation.find(\"infon[@key='type']\")\n",
        "                if ann_type is not None and ann_type.text == \"Gene\":\n",
        "                    # Check for both 'identifier' and 'NCBI Gene' keys.\n",
        "                    gene_id_elem = annotation.find(\"infon[@key='identifier']\")\n",
        "                    if gene_id_elem is None:\n",
        "                        gene_id_elem = annotation.find(\"infon[@key='NCBI Gene']\")\n",
        "                    gene_id = gene_id_elem.text if gene_id_elem is not None else None\n",
        "\n",
        "                    # Handle multiple IDs by keeping only the first if needed.\n",
        "                    if gene_id and \";\" in gene_id:\n",
        "                        gene_id = gene_id.split(\";\")[0].strip()\n",
        "\n",
        "                    # Extract the gene name from the annotation text.\n",
        "                    in_text_gene_name_elem = annotation.find(\"text\")\n",
        "                    in_text_gene_name = in_text_gene_name_elem.text if in_text_gene_name_elem is not None else None\n",
        "\n",
        "                    # Extract the annotation location (offset) to find the sentence.\n",
        "                    location_elem = annotation.find(\"location\")\n",
        "                    ann_offset = int(location_elem.attrib.get('offset', 0)) if location_elem is not None else 0\n",
        "\n",
        "                    # Determine which sentence contains the annotation based on its offset.\n",
        "                    sentence_index = None\n",
        "                    for i, start in enumerate(start_indices):\n",
        "                        if start <= ann_offset < start + len(sentences[i]):\n",
        "                            sentence_index = i\n",
        "                            break\n",
        "\n",
        "                    if sentence_index is not None and gene_id:\n",
        "                        if gene_id not in gene_annotations:\n",
        "                            gene_annotations[gene_id] = {'indices': [], 'name': in_text_gene_name}\n",
        "                        gene_annotations[gene_id]['indices'].append(sentence_index)\n",
        "\n",
        "            # For each gene in this passage, process the annotation indices.\n",
        "            for gene_id, data in gene_annotations.items():\n",
        "                # Remove duplicate indices and sort.\n",
        "                indices = sorted(set(data['indices']))\n",
        "                candidate_windows = []\n",
        "                # For each annotation occurrence, form a candidate window:\n",
        "                # one sentence before and one sentence after the annotated sentence.\n",
        "                for idx in indices:\n",
        "                    start_sentence = max(0, idx - 1)\n",
        "                    end_sentence = min(len(sentences), idx + 2)  # end index is non-inclusive\n",
        "                    candidate_windows.append((start_sentence, end_sentence))\n",
        "                # Merge overlapping candidate windows.\n",
        "                merged_windows = []\n",
        "                for window in sorted(candidate_windows):\n",
        "                    if not merged_windows:\n",
        "                        merged_windows.append(window)\n",
        "                    else:\n",
        "                        last = merged_windows[-1]\n",
        "                        # If windows overlap or touch, merge them.\n",
        "                        if window[0] <= last[1]:\n",
        "                            merged_windows[-1] = (last[0], max(last[1], window[1]))\n",
        "                        else:\n",
        "                            merged_windows.append(window)\n",
        "                # For each merged window, if it spans more than 3 sentences, split it into chunks of 3 sentences maximum.\n",
        "                for window in merged_windows:\n",
        "                    start, end = window\n",
        "                    window_size = end - start\n",
        "                    if window_size <= 3:\n",
        "                        snippet = \" \".join(sentences[start:end])\n",
        "                        if gene_id in gene_dict:\n",
        "                            gene_dict[gene_id].add_occurrence(snippet)\n",
        "                        else:\n",
        "                            gene_obj = Gene(gene_id)\n",
        "                            gene_obj.add_occurrence(snippet)\n",
        "                            gene_obj.set_doc_id(doc_id)\n",
        "                            gene_obj.set_name_from_article(data['name'])\n",
        "                            gene_dict[gene_id] = gene_obj\n",
        "                    else:\n",
        "                        # Split the merged window into non-overlapping chunks of at most 3 sentences.\n",
        "                        for i in range(start, end, 3):\n",
        "                            chunk_end = min(i + 3, end)\n",
        "                            snippet = \" \".join(sentences[i:chunk_end])\n",
        "                            if snippet.strip():\n",
        "                                if gene_id in gene_dict:\n",
        "                                    gene_dict[gene_id].add_occurrence(snippet)\n",
        "                                else:\n",
        "                                    gene_obj = Gene(gene_id)\n",
        "                                    gene_obj.set_doc_id(doc_id)\n",
        "                                    gene_obj.add_occurrence(snippet)\n",
        "                                    gene_obj.set_name_from_article(data['name'])\n",
        "                                    gene_dict[gene_id] = gene_obj\n",
        "    return gene_dict\n",
        "\n",
        "def fetch_and_update_gene_info(gene_dict):\n",
        "    \"\"\"Retrieves gene information from NCBI and updates the genes in gene_dict.\"\"\"\n",
        "    gene_ids = list(gene_dict.keys())\n",
        "    if gene_ids:\n",
        "        # Post the gene IDs to NCBI.\n",
        "        handle = Entrez.epost(db=\"gene\", id=\",\".join(gene_ids))\n",
        "        result = Entrez.read(handle)\n",
        "        handle.close()\n",
        "\n",
        "        webenv = result[\"WebEnv\"]\n",
        "        query_key = result[\"QueryKey\"]\n",
        "\n",
        "        handle = Entrez.esummary(db=\"gene\", webenv=webenv, query_key=query_key)\n",
        "        record = Entrez.read(handle)\n",
        "        handle.close()\n",
        "\n",
        "        for docsum in record[\"DocumentSummarySet\"][\"DocumentSummary\"]:\n",
        "            gene_id = docsum.attributes[\"uid\"]\n",
        "            symbol = docsum.get('NomenclatureSymbol', 'No symbol')\n",
        "            organism = docsum.get('Organism', {}).get('ScientificName', 'No organism')\n",
        "            full_name = docsum.get('NomenclatureName', gene_dict[gene_id].get_name_from_article())\n",
        "            also_known_as = docsum.get('OtherAliases', gene_dict[gene_id].get_name_from_article())\n",
        "\n",
        "            if full_name == '':\n",
        "                full_name = gene_dict[gene_id].get_name_from_article()\n",
        "            if also_known_as == '':\n",
        "                also_known_as = gene_dict[gene_id].get_name_from_article()\n",
        "\n",
        "            if gene_id in gene_dict:\n",
        "                gene_dict[gene_id].update_info(symbol, organism, full_name, also_known_as)\n",
        "            time.sleep(0.5)  # Pause briefly to avoid overwhelming NCBI servers.\n",
        "\n",
        "# Set your email (and API key if available)\n",
        "Entrez.email = \"email here\"\n",
        "# Entrez.api_key = \"your_api_key\"\n",
        "\n",
        "xml_path = \"./output/PMC10669939.xml\"\n",
        "gene_dict = parse_xml_file(xml_path)\n",
        "fetch_and_update_gene_info(gene_dict)  # Optionally fetch gene info from NCBI\n",
        "\n",
        "print(\"There are {} genes in the paper.\".format(len(gene_dict)))\n",
        "if len(gene_dict) == 0:\n",
        "    print(\"No genes found in the paper.\")\n",
        "else:\n",
        "    for gene in gene_dict.values():\n",
        "        print(gene)\n",
        "        print(f\"There are {len(gene.get_occurrences())} occurrence(s) (each occurrence is at most 3 sentences long) for gene {gene.get_gene_id()} : {gene.get_name_from_article()}.\")\n",
        "        print(\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33A7yYBLXZes"
      },
      "source": [
        "# 3.5 Prompt Engineering\n",
        "- Creates the prompt using the Gene dictionary (from Gene chunking)\n",
        "- batch_size: allows you to have more than 1 Gene in the prompt such that you have something like the following. Ideally keep it at batch_size=1 to ensure that the GO terms generated are exclusive to the Gene being analyzed.\n",
        "\n",
        "```\n",
        "# batch_size > 1 has the basic format:\n",
        "Basic Prompt\n",
        "Gene 1\n",
        "Gene 2\n",
        "...\n",
        "# batch_size = 1 has the basic format:\n",
        "Basic Prompt\n",
        "Gene 1\n",
        "```\n",
        "- batch_index: allows you to iterate through the gene dictionary so that if you have a paper with x amount of genes, you can just increment  the index and run the inference x amount of times.\n",
        "- direct: ignore this. This is for the future.\n",
        "- customized_prompt: ignore this as well. This is for the future."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsRz3Wb5YTQl",
        "outputId": "dc245a37-b770-4af2-f071-f0b973bda774"
      },
      "outputs": [],
      "source": [
        "def make_go_term_prompt(gene_dict, batch_size=1, batch_index=0, direct=False, customized_prompt=None):\n",
        "    \"\"\"\n",
        "    Create a prompt for Llama to output Gene Ontology (GO) terms (without IDs) for a batch of genes\n",
        "    from the gene dictionary. The output is expected to be categorized into three sections for each gene:\n",
        "      1. Biological Processes\n",
        "      2. Cellular Components\n",
        "      3. Molecular Functions\n",
        "\n",
        "    For each gene, the output should follow the format below without mixing results across different genes.\n",
        "\n",
        "    :param gene_dict: A dictionary where each key is a gene ID and each value is a Gene object that\n",
        "                      contains attributes such as symbol, organism, full_name, and occurrences.\n",
        "    :param batch_size: The number of genes to include in this prompt batch.\n",
        "    :param batch_index: The index (0-based) of the batch to process. For instance, if batch_size=1,\n",
        "                        batch_index=2 will include the 3rd gene in the dictionary.\n",
        "    :param direct: If True, use a more direct instruction for GO term extraction.\n",
        "    :param customized_prompt: If provided, use this custom prompt text in place of the default.\n",
        "    :return: A string containing the complete prompt.\n",
        "    \"\"\"\n",
        "\n",
        "    # Instruction blocks\n",
        "\n",
        "    # context = \"\"\"You are an efficient and insightful assistant to a geneticist.\"\"\"\n",
        "\n",
        "    general_instructions = \"\"\"Analyze the following gene information and text snippets under \"Occurrences\".\n",
        "Identify all potentially relevant Gene Ontology (GO) terms using only evidence explicitly stated in the text.\n",
        "Do not include any GO terms based on inferences or assumptions not explicitly supported by the text.\n",
        "\n",
        "After completing your analysis, for each Gene Ontology (GO) term you list, provide a short one-line justification referencing the text as well as a relationship between the gene and the term.\n",
        "If the text does not explicitly support a GO term (even if it might be inferred), do not include it. If no GO term is supported for a particular gene, say “None found.”\n",
        "\n",
        "Be concise, do not use unnecessary words.\n",
        "Be factual, do not editorialize.\n",
        "Be specific, avoid overly general statements like \"it is involved in many cellular processes\".\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    example = \"\"\"To help you in your work, I am providing an example of gene information and the corresponding example analysis output structured in JSON.\n",
        "\n",
        "Example gene information is:\n",
        "Gene: myogenin\n",
        "Organism: Mus musculus\n",
        "Occurrences:\n",
        "- Activation of NF-kappaB increases the expression of the inducible nitric oxide synthase (iNOS) in muscle cells that sequester HuR (RNA-binding protein) by preventing transcription of MyoD. Denervation-induced atrophy is related to the upregulation of specific histone deacetylases (HDAC), able to repress a negative regulator of myogenin, with an increase in MuRF1 expression and muscle wasting. AMPK (protein kinase activated by 5'adenosine monophosphate) is also involved in muscle atrophy.\n",
        "\n",
        "Example anaylysis output is:\n",
        "[\n",
        "  {\n",
        "    \"gene\": \"myogenin\",\n",
        "    \"go_data\": [\n",
        "      {\n",
        "        \"term\": \"DNA-binding transcription activator activity\",\n",
        "        \"relationship\": \"enables\",\n",
        "        \"namespace\": \"molecular_function\",\n",
        "        \"justification\": \"Myogenin is a key transcription factor in muscle differentiation that binds to E-box sequences in muscle-specific genes and activates their transcription through RNA polymerase II.\"\n",
        "      },\n",
        "      {\n",
        "        \"term\": \"skeletal muscle cell differentiation\",\n",
        "        \"relationship\": \"involved_in\",\n",
        "        \"namespace\": \"biological_process\",\n",
        "        \"justification\": \"Myogenin is one of the four myogenic regulatory factors (MRFs) that drive skeletal muscle differentiation by promoting the transition from myoblasts to myotubes.\"\n",
        "      },\n",
        "      {\n",
        "        \"term\": \"nucleus\",\n",
        "        \"relationship\": \"located_in\",\n",
        "        \"namespace\": \"cellular_component\",\n",
        "        \"justification\": \"As a transcription factor, myogenin localizes to the nucleus to regulate the expression of muscle-specific genes.\"\n",
        "      }\n",
        "    ]\n",
        "  }\n",
        "]\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "    # Assemble the prompt text based on the chosen mode\n",
        "    if direct:\n",
        "        # prompt_text = context\n",
        "        # prompt_text += direct_instructions\n",
        "        # prompt_text += format_instructions\n",
        "        # prompt_text += example_output\n",
        "        pass\n",
        "    elif customized_prompt:\n",
        "        # prompt_text = context\n",
        "        # prompt_text += customized_prompt\n",
        "        # prompt_text += format_instructions\n",
        "        # prompt_text += example_output\n",
        "        pass\n",
        "    else:\n",
        "        prompt_text = general_instructions\n",
        "        prompt_text += example\n",
        "        prompt_text += \"\\nHere is the gene information:\\n\"\n",
        "\n",
        "    # Convert the gene dictionary to a list and determine the batch slice.\n",
        "    gene_items = list(gene_dict.items())\n",
        "    start_index = batch_index * batch_size\n",
        "    end_index = start_index + batch_size\n",
        "    batch_genes = gene_items[start_index:end_index]\n",
        "\n",
        "    # Add details and occurrence context for each gene in the selected batch.\n",
        "    for gene_id, gene_obj in batch_genes:\n",
        "        # prompt_text += f\"\\nGene ID: {gene_id}\\n\"\n",
        "        # prompt_text += f\"Symbol: {gene_obj.symbol}\\n\"\n",
        "        # prompt_text += f\"Organism: {gene_obj.organism}\\n\"\n",
        "        # prompt_text += f\"Full Name: {gene_obj.full_name}\\n\"\n",
        "        prompt_text += f\"\\nGene: {gene_obj.get_name_from_article()}\\n\"\n",
        "        if gene_obj.get_organsim() != None:\n",
        "          # add organism if available\n",
        "          prompt_text += f\"Organism: {gene_obj.get_organsim()}\\n\"\n",
        "        prompt_text += \"Occurrences:\\n\"\n",
        "        for occ in gene_obj.occurrences:\n",
        "            prompt_text += f\"- {occ}\\n\"\n",
        "\n",
        "    return prompt_text\n",
        "\n",
        "# Example usage:\n",
        "# Assuming gene_dict is defined and contains Gene objects with attributes: symbol, organism, full_name, and occurrences.\n",
        "# To process only one gene at a time:\n",
        "# prompt = make_go_term_prompt(gene_dict, batch_size=1, batch_index=0)\n",
        "# print(prompt)\n",
        "\n",
        "# prompt = make_go_term_prompt(gene_dict, batch_size=116, batch_index=0)\n",
        "# print(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oaKSo6iXGOc"
      },
      "source": [
        "# 4. Inference (Local)\n",
        "The two cells below rely on local inference meaning that you must have the model locally. Skip them if youre using the API like GROQ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzFESXHRXBHG"
      },
      "outputs": [],
      "source": [
        "print(\"Loading LLaMA model.\")\n",
        "# model_dir = \"/content/drive/MyDrive/Llama 3.2-3B-Instruct-model\"\n",
        "model_dir = \"/content/drive/MyDrive/GOLLM/Llama 3.2-3B-Instruct-model\"\n",
        "device = torch.device(\"cuda\")\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_dir, local_files_only=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_dir, local_files_only=True).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzBYJajjYYly"
      },
      "outputs": [],
      "source": [
        "def run_inference(prompt):\n",
        "    \"\"\"\n",
        "    Run inference on the provided prompt using the specified model and tokenizer.\n",
        "\n",
        "    :param prompt: The prompt string to send to the model.\n",
        "    :return: The generated text.\n",
        "    \"\"\"\n",
        "\n",
        "    # Encode the prompt and move to the appropriate device\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "    attention_mask = inputs[\"attention_mask\"]\n",
        "\n",
        "    # Greedy or minimal variation == When: You want consistent, short answers, and you don’t mind if it’s a bit “blunt.”\n",
        "    # outputs = model.generate(\n",
        "    #     input_ids=inputs[\"input_ids\"],\n",
        "    #     attention_mask=attention_mask,\n",
        "    #     max_new_tokens=150,\n",
        "    #     do_sample=False,     # no sampling\n",
        "    #     num_beams=1,         # purely greedy\n",
        "    #     no_repeat_ngram_size=3,\n",
        "    #     pad_token_id=tokenizer.eos_token_id\n",
        "    # )\n",
        "\n",
        "    # Beam Search (Higher Quality / Less Randomness) == You want a more “global optimum” text.\n",
        "    # outputs = model.generate(\n",
        "    #     input_ids=inputs[\"input_ids\"],\n",
        "    #     attention_mask=attention_mask,\n",
        "    #     max_new_tokens=200,\n",
        "    #     do_sample=False,\n",
        "    #     num_beams=4,      # search multiple beams\n",
        "    #     length_penalty=1.0,  # see if you want to encourage or discourage long outputs\n",
        "    #     no_repeat_ngram_size=3,\n",
        "    #     pad_token_id=tokenizer.eos_token_id\n",
        "    # )\n",
        "\n",
        "    # Beam SearchV2\n",
        "    outputs = model.generate(\n",
        "        input_ids=inputs[\"input_ids\"],\n",
        "        attention_mask=attention_mask,\n",
        "        max_new_tokens=400,       # Enough tokens for a concise but thorough answer\n",
        "        do_sample=False,          # Turn off sampling; we want a more deterministic, stable answer\n",
        "        num_beams=3,              # Explore multiple beams for higher-quality completions\n",
        "        length_penalty=0.1,       # 1.0 means \"neutral\" length preference (>=1.0 encourages longer outputs)\n",
        "        no_repeat_ngram_size=4,   # Helps avoid repeating the same phrase\n",
        "        early_stopping=True,      # Stops as soon as the best beam is complete\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        temperature=None,\n",
        "        top_p=None,\n",
        "    )\n",
        "    # Sampling (More Creative / Less Deterministic)\n",
        "    # outputs = model.generate(\n",
        "    #     input_ids=inputs[\"input_ids\"],\n",
        "    #     attention_mask=attention_mask,\n",
        "    #     max_new_tokens=200,\n",
        "    #     do_sample=True,       # sampling\n",
        "    #     temperature=0.7,      # moderate creativity\n",
        "    #     top_p=0.9,            # nucleus sampling\n",
        "    #     no_repeat_ngram_size=3,\n",
        "    #     pad_token_id=tokenizer.eos_token_id\n",
        "    # )\n",
        "\n",
        "    # Decode the output and return the generated text\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    completion = generated_text[len(prompt):].strip()\n",
        "    return completion\n",
        "\n",
        "for i in range(3):\n",
        "    start_time = time.time()\n",
        "    output = run_inference(test_prompt)\n",
        "    print(output)\n",
        "\n",
        "    # with open(f'/content/drive/MyDrive/GOLLM/Inference Outputs/output_{i+1}.txt', 'w') as file:\n",
        "    #     file.write(output)\n",
        "\n",
        "    print(f\"-->Model loaded on {device} named {torch.cuda.get_device_name(0)} and it took {time.time()-start_time:.2f} seconds.\")\n",
        "    print(\"-\"*50)\n",
        "\n",
        "# prompt = \"what is 2+2\"\n",
        "# print(\"Running inference...\")\n",
        "# start_time = time.time()\n",
        "# output = run_inference(prompt)\n",
        "# print(f\"Model loaded on {device} in {time.time()-start_time:.2f} seconds.\")\n",
        "# print(output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSz3gKoaY7yu"
      },
      "source": [
        "# 4v2. GROQ API Inference\n",
        "- need API Key\n",
        "- uses llama 3.3-70b-versatile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_k_yNbOwpkb",
        "outputId": "16a5c4d1-e0bd-4c8b-a736-77a7dd2e2130"
      },
      "outputs": [],
      "source": [
        "# using GROQ API\n",
        "!pip install Groq\n",
        "from groq import Groq\n",
        "\n",
        "client = Groq(\n",
        "    api_key=\"\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmOgXgUc_DAC"
      },
      "source": [
        "## Run it again if it stops. It will skip documents that already exists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eOnOkZsztbK",
        "outputId": "f9dbfdd0-0f1e-4238-cfb7-7cca62af4790"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import tempfile\n",
        "import shutil \n",
        "\n",
        "# Create a temporary directory to store individual JSON outputs.\n",
        "temp_dir = os.path.join(os.getcwd(), \"temp_inferences\")\n",
        "if not os.path.exists(temp_dir):\n",
        "    os.makedirs(temp_dir)\n",
        "# Create a  directory to store individual llama JSON outputs.\n",
        "llama_dir = os.path.join(os.getcwd(), \"llama_inferences\")\n",
        "if not os.path.exists(llama_dir):\n",
        "    os.makedirs(llama_dir)\n",
        "\n",
        "# retrieve the doc_id from the gene_dict of any gene (since all genes in the gene_dict are from the same document)\n",
        "doc_id = None\n",
        "for gene in gene_dict.values():\n",
        "    if gene.get_doc_id() is not None:\n",
        "        doc_id = gene.get_doc_id()\n",
        "        break\n",
        "\n",
        "# Create a subdirectory under temp_inferences named after doc_id.\n",
        "# If doc_id is None, fall back to a placeholder name, e.g. \"unknown_doc_id\".\n",
        "temp_doc_dir = os.path.join(temp_dir, doc_id if doc_id else \"unknown_doc_id\")\n",
        "if not os.path.exists(temp_doc_dir):\n",
        "    os.makedirs(temp_doc_dir)\n",
        "\n",
        "# List of gene items from gene_dict\n",
        "gene_items = list(gene_dict.items())\n",
        "final_results = []\n",
        "\n",
        "# Process each gene one-by-one (batch_size=1)\n",
        "for idx, (gene_id, gene_obj) in enumerate(gene_items):\n",
        "    output_filename = os.path.join(temp_doc_dir, f\"gene_{gene_id}.json\")\n",
        "\n",
        "    # Check if the gene's output file already exists\n",
        "    if os.path.exists(output_filename):\n",
        "        print(f\"Skipping gene {gene_id}: output file already exists.\")\n",
        "        try:\n",
        "            with open(output_filename, \"r\", encoding=\"utf-8\") as f:\n",
        "                gene_output = f.read()\n",
        "            final_results.append(json.loads(gene_output))\n",
        "        except json.JSONDecodeError:\n",
        "            print(f\"Warning: Existing output for gene {gene_id} is not valid JSON.\")\n",
        "        continue\n",
        "\n",
        "    # Generate a prompt for a single gene.\n",
        "    prompt = make_go_term_prompt(gene_dict, batch_size=1, batch_index=idx)\n",
        "    # Use your GROQ API client to request the inference.\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt},\n",
        "        ],\n",
        "        model=\"llama-3.3-70b-versatile\",\n",
        "        temperature=0,\n",
        "        max_completion_tokens=4096,\n",
        "        top_p=0.5,\n",
        "        stream=False,\n",
        "        response_format={\"type\": \"json_object\"},\n",
        "        stop=None,\n",
        "    )\n",
        "\n",
        "    # Extract the JSON output from the response.\n",
        "    gene_output = chat_completion.choices[0].message.content\n",
        "\n",
        "    # Add the output to the final results list.\n",
        "    try:\n",
        "        model_json = json.loads(gene_output)\n",
        "\n",
        "        # Construct a new dict to ensure key order: gene, geneID, go_data\n",
        "        ordered_model_json = {\n",
        "            \"gene\": model_json.get(\"gene\", \"\"),\n",
        "            \"geneID\": gene_id,\n",
        "            \"go_data\": model_json.get(\"go_data\", [])\n",
        "        }\n",
        "\n",
        "        # If go_data is not a list, set it to an empty list\n",
        "        if not isinstance(ordered_model_json[\"go_data\"], list):\n",
        "            ordered_model_json[\"go_data\"] = []\n",
        "\n",
        "        # Add reference(s) to each GO entry\n",
        "        for entry in ordered_model_json[\"go_data\"]:\n",
        "            entry[\"reference(s)\"] = [gene_obj.get_doc_id()]\n",
        "\n",
        "        # Save the updated JSON in the temp folder\n",
        "        with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(ordered_model_json, f, indent=2)\n",
        "\n",
        "        final_results.append(ordered_model_json)\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Warning: Output for gene {gene_id} is not valid JSON.\")\n",
        "\n",
        "# Merge all outputs into one finalized JSON file, using doc_id in the filename\n",
        "llama_output_path = os.path.join(llama_dir, f\"llama_output_{doc_id}.json\")\n",
        "with open(llama_output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(final_results, f, indent=2)\n",
        "\n",
        "print(f\"Finished processing {len(gene_items)} genes. Final merged JSON saved to {llama_output_path}\")\n",
        "\n",
        "# Remove the temporary directory\n",
        "# shutil.rmtree(temp_dir)\n",
        "# print(f\"Removed temporary folder: {temp_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P58Ns1lwdbbg"
      },
      "source": [
        "# 5. Normalize\n",
        "- use an embedding model (SAPBERT) to ensure that the terms generated by Llama are actual GO terms. You will need the Go.obo file from the [Gene Ontology Consortium](https://geneontology.org/docs/download-ontology/)\n",
        "  - Essentially, for each go term created by Llama, Sapbert will do a similarity search against the Go.obo and retrieve the actual term + GO:ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5lKdeAZ1Ssh",
        "outputId": "31f1d594-43c0-4f83-e46c-4873128724d0"
      },
      "outputs": [],
      "source": [
        "# Install required packages (run these in your environment if not already installed)\n",
        "!pip install sentence-transformers\n",
        "!pip install obonet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TPMPZKF1P1X",
        "outputId": "80689670-c815-40d7-8bb8-d202d1fc88c4"
      },
      "outputs": [],
      "source": [
        "import obonet\n",
        "import json\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import numpy as np\n",
        "\n",
        "##########################################\n",
        "# 1. Load and parse the GO.obo file\n",
        "##########################################\n",
        "\n",
        "def load_go_ontology(obo_filepath):\n",
        "    \"\"\"\n",
        "    Parse the GO.obo file using obonet.\n",
        "    Returns a dictionary mapping GO IDs to their term names.\n",
        "    \"\"\"\n",
        "    graph = obonet.read_obo(obo_filepath)\n",
        "    go_terms = {}\n",
        "    for go_id, data in graph.nodes(data=True):\n",
        "        # Only include nodes that have a 'name' field\n",
        "        if 'name' in data:\n",
        "            go_terms[go_id] = data\n",
        "    return go_terms\n",
        "\n",
        "# set the path to your local go.obo (or something else later) file\n",
        "obo_file = \"C:/Users/aivan/Desktop/BIOIN 401/Go Files/go.obo\"\n",
        "go_terms_dict = load_go_ontology(obo_file)\n",
        "print(f\"Loaded {len(go_terms_dict)} GO terms from {obo_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340,
          "referenced_widgets": [
            "e4718c03421b41a2a665c26293acd697",
            "7d97b347b7cb40df81041035931d7f27",
            "b85f6bb59d024282b5552ff665da4548",
            "f1219528a46a4a8e94bd1c8de9e6e16a",
            "1b8c25318a2b4b64bab3496083679c85",
            "53bb7f0fbad34a818e266d0ea44ffaf1",
            "bc435a026437452bb820c14d1ce5d3ee",
            "47571c7570f14ab58f96e5d30129da1b",
            "ec42f776af1b48a982636f0c122ab7e6",
            "de6e3ef0670042378384c41ecd695f1a",
            "ec7200455fa34863bec2ae60f9f4aad5",
            "618fd6a5462e4c5296b560f888b5d638",
            "331dbfdb6d7849c6a7b6d43bd33a7325",
            "54a0cadcc9ef406db05d36b690d7891c",
            "2443ed122977428c98248537123b674b",
            "c3911d8aca764dd38fad4c1dded8198f",
            "8eb65674477e477091f2501704df7eb8",
            "6d29b58c64cc4f869d6944699149a60e",
            "c939f017049643b18d5142514937af73",
            "6c463c9a4bef4b5194113acf7ced731e",
            "f7dcd748d0944da09948f4372366e8a8",
            "466f8ef6ba644d31a8586abaf9830448",
            "6ac927f5e2a2453d9aae4b5c474cf96d",
            "7593152124e04332b709dd30ec87c5a5",
            "4a743c94312c4b5db25087a747f6b879",
            "59dc6c4216cb4c5aad8c3764cf3d3f6d",
            "3117723c389b4e47a97d6e582078e5c9",
            "c6b5cf46fbeb41adb8da935949b808c1",
            "d4b8ff5330d14128ba304020f7fe8412",
            "ea731973ab9c44caa479fb7934fd3b4f",
            "097046dc7c4f46f5866068c82b706aca",
            "cc7573c531c84e61999e2161710173f3",
            "9775c0cd37bc43dcb7953f8b15343332",
            "1675d70c8a5e426691d0af5e6ba333f3",
            "784d7bf8c3be48b8ad5a3b6e6954690f",
            "730fe49f91204e2cbd3b58d24442be0a",
            "792eb1f8daf34e2590fda2f60e3ff684",
            "3e0f9cdf58ef4af1a0b16f9795747dfc",
            "1845ddb7ff634d969fa2538209fc4e0a",
            "9b03af45365c42419bb39779b82be47c",
            "d598fdb3d94a4095ba5a950cef321f1b",
            "39794838a2164151a5edf298a63f8147",
            "e7eaa149a903445db37dfdf719e14f9e",
            "4af857d8e5a94c278ae0fb3d7e092ac5",
            "769b37c671334690b6a7e5ba9059343e",
            "bdf351e0ccbc4aa18e168f593d1659cf",
            "8901a8884437441c934c53a98a1dac06",
            "32ef3e232304493d8b7e129c679f4f6f",
            "77472246b6b0497fbe67b8a3529040e5",
            "61de99be2c2e4afe90ff06e3bb30a2b7",
            "873ea6832a0447a19938fe764cb7ac58",
            "b483173c5fa74a72bb0a88206d3206a3",
            "8039b35f8f654a5e93ab69a0d1d8f3ea",
            "b1c01cfdd57e40e7bc4de9baf81d9f45",
            "82a3774cc5cd4acfb1822d9cb74d6f45"
          ]
        },
        "id": "zfuUI3PF1boL",
        "outputId": "e257d393-bdbb-4695-d2ac-d8f2ee4ecbea"
      },
      "outputs": [],
      "source": [
        "##########################################\n",
        "# 2. Load the SAPBERT embedding model (or an alternative)\n",
        "##########################################\n",
        "\n",
        "# Here we use a SAPBERT model available from Hugging Face.\n",
        "# may choose another model (e.g., \"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "model_name = \"cambridgeltl/SapBERT-from-PubMedBERT-fulltext\"  # SAPBERT model fine-tuned on UMLS\n",
        "sapbert_model = SentenceTransformer(model_name)\n",
        "print(f\"Loaded embedding model: {model_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OM1So4sX2JLT",
        "outputId": "8477c5ed-2546-409c-8284-f1d957453bde"
      },
      "outputs": [],
      "source": [
        "def embed_go_terms(go_terms, model):\n",
        "    \"\"\"\n",
        "    Given a dictionary of GO terms (GO ID -> term data) and an embedding model,\n",
        "    returns:\n",
        "      - a list of GO IDs,\n",
        "      - a list of GO term names (in the same order),\n",
        "      - a tensor of embeddings for the GO term names,\n",
        "      - a list of GO namespaces,\n",
        "      - a list of GO relationships (if available, otherwise default to 'unknown')\n",
        "    \"\"\"\n",
        "    go_ids = []\n",
        "    go_names = []\n",
        "    go_namespaces = []\n",
        "    go_relationships = []\n",
        "\n",
        "    for go_id, data in go_terms.items():\n",
        "        if 'name' in data:\n",
        "            go_ids.append(go_id)\n",
        "            go_names.append(data['name'])\n",
        "            go_namespaces.append(data.get('namespace', 'unknown'))\n",
        "            # Some GO entries might not have a \"relationship\" field; default to 'unknown'\n",
        "            go_relationships.append(data.get('relationship', 'unknown'))\n",
        "\n",
        "    go_embeddings = model.encode(go_names, convert_to_tensor=True)\n",
        "    return go_ids, go_names, go_embeddings, go_namespaces, go_relationships\n",
        "\n",
        "# Reload GO ontology using the updated load_go_ontology:\n",
        "# go_terms_dict = load_go_ontology(obo_file) # already loaded in the previous cell\n",
        "go_ids, go_names, go_embeddings, go_namespaces, go_relationships = embed_go_terms(go_terms_dict, sapbert_model)\n",
        "print(\"Embedded GO terms with additional metadata.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0yR2eF6228J",
        "outputId": "3bfeca3b-8998-4598-f8f4-56505af53917"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def get_best_matching_go_term(llama_term, go_ids, go_names, go_embeddings, model, threshold=0.6):\n",
        "    \"\"\"\n",
        "    Given a GO term from Llama, compute its embedding and find the best matching GO term\n",
        "    from the provided GO ontology embeddings.\n",
        "\n",
        "    Parameters:\n",
        "      - llama_term: The GO term string generated by Llama.\n",
        "      - go_ids, go_names, go_embeddings: Outputs from embed_go_terms().\n",
        "      - model: The embedding model.\n",
        "      - threshold: Minimum cosine similarity required to accept the match.\n",
        "\n",
        "    Returns:\n",
        "      - best_go_id: The GO:ID of the best match (or None if score is below threshold)\n",
        "      - best_go_name: The GO term name of the best match.\n",
        "      - best_score: The cosine similarity score.\n",
        "    \"\"\"\n",
        "    # Encode the query using the model\n",
        "    query_embedding = model.encode(llama_term, convert_to_tensor=True)\n",
        "    # Compute cosine similarities between the query and all GO term embeddings\n",
        "    cos_scores = torch.squeeze(util.cos_sim(query_embedding, go_embeddings))\n",
        "    # Use torch.argmax to find the best matching index\n",
        "    best_idx = torch.argmax(cos_scores)\n",
        "    best_score = cos_scores[best_idx].item()\n",
        "\n",
        "    if best_score >= threshold:\n",
        "        return go_ids[best_idx], go_names[best_idx], best_score, best_idx\n",
        "    else:\n",
        "        return None, None, best_score, None\n",
        "\n",
        "# Test the matching function with an example Llama-generated term:\n",
        "example_llama_term = \"muscle cell differentiation\"\n",
        "best_go_id, best_go_name, score, best_idx = get_best_matching_go_term(example_llama_term, go_ids, go_names, go_embeddings, sapbert_model)\n",
        "print(f\"Example: Llama term '{example_llama_term}' matched with '{best_go_name}' ({best_go_id}) with score {score:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zp0nhP0_3pHz",
        "outputId": "331efcf4-a0ca-4146-ceab-abf18abd3981"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def parse_llama_output(llama_output_path):\n",
        "    \"\"\"\n",
        "    Parses Llama's output JSON file.\n",
        "    Returns the parsed JSON data (a list of gene entries).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(llama_output_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "        # If the JSON is a single dictionary, convert it to a list\n",
        "        if isinstance(data, dict):\n",
        "            data = [data]\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing JSON: {e}\")\n",
        "        return []\n",
        "\n",
        "# print(parse_llama_output(\"./llama_inferences/llama_output_22118460))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpyVuCmM_EtU",
        "outputId": "c8d869f2-162d-4661-cf94-91f28390fa6e"
      },
      "outputs": [],
      "source": [
        "def auto_match_go_terms(llama_data, go_ids, go_names, go_embeddings, go_namespaces, go_relationships, model, threshold=0.6):\n",
        "    \"\"\"\n",
        "    Given parsed Llama JSON data, match each Llama-generated GO term to the best official GO term.\n",
        "    \"\"\"\n",
        "    matched_go_terms = {}\n",
        "\n",
        "    # If the JSON is nested under \"genes\", extract that list.\n",
        "    if isinstance(llama_data, list) and len(llama_data) > 0 and \"genes\" in llama_data[0]:\n",
        "        gene_entries = llama_data[0][\"genes\"]\n",
        "    else:\n",
        "        gene_entries = llama_data\n",
        "\n",
        "    for gene_entry in gene_entries:\n",
        "        gene_name = gene_entry.get(\"gene\", \"UnknownGene\")\n",
        "        gene_id = gene_entry.get(\"geneID\", \"UnknownID\")     # using id instead of name for the dictionary since some genes have the same name\n",
        "        go_data = gene_entry.get(\"go_data\", [])\n",
        "        unique_matches = {}\n",
        "\n",
        "        for entry in go_data:\n",
        "            llama_term = entry.get(\"term\")\n",
        "            if not llama_term:\n",
        "                continue\n",
        "\n",
        "            best_go_id, best_go_name, best_score, best_idx = get_best_matching_go_term(\n",
        "                llama_term, go_ids, go_names, go_embeddings, model, threshold=threshold\n",
        "            )\n",
        "\n",
        "            if best_go_id and best_idx is not None:\n",
        "                official_relationship = go_relationships[best_idx]\n",
        "                official_namespace = go_namespaces[best_idx]\n",
        "\n",
        "                if best_go_id in unique_matches:\n",
        "                    if best_score > unique_matches[best_go_id][\"similarity\"]:\n",
        "                        unique_matches[best_go_id] = {\n",
        "                            \"llama_term\": llama_term,\n",
        "                            \"matched_go_id\": best_go_id,\n",
        "                            \"matched_go_name\": best_go_name,\n",
        "                            \"similarity\": best_score,\n",
        "                            \"relationship\": official_relationship,\n",
        "                            \"namespace\": official_namespace,\n",
        "                            \"justification\": entry.get(\"justification\")\n",
        "                        }\n",
        "                else:\n",
        "                    unique_matches[best_go_id] = {\n",
        "                        \"llama_term\": llama_term,\n",
        "                        \"matched_go_id\": best_go_id,\n",
        "                        \"matched_go_name\": best_go_name,\n",
        "                        \"similarity\": best_score,\n",
        "                        \"relationship\": official_relationship,\n",
        "                        \"namespace\": official_namespace,\n",
        "                        \"justification\": entry.get(\"justification\")\n",
        "                    }\n",
        "\n",
        "        matched_go_terms[gene_id] = list(unique_matches.values())\n",
        "\n",
        "    return matched_go_terms\n",
        "\n",
        "def replace_terms_with_go(llama_data, matched_go_terms, similarity_threshold=0.65):\n",
        "    \"\"\"\n",
        "    Replaces each llama_data entry's GO term with the matched GO term info from matched_go_terms.\n",
        "    \"\"\"\n",
        "    # If llama_data is nested under \"genes\", re-point gene_entries\n",
        "    if isinstance(llama_data, list) and len(llama_data) > 0 and \"genes\" in llama_data[0]:\n",
        "        gene_entries = llama_data[0][\"genes\"]\n",
        "    else:\n",
        "        gene_entries = llama_data\n",
        "\n",
        "    for gene_entry in gene_entries:\n",
        "        gene_id = gene_entry.get(\"geneID\")\n",
        "        if gene_id in matched_go_terms:\n",
        "            new_go_data = []\n",
        "            for match in matched_go_terms[gene_id]:\n",
        "                # Skip if the match similarity is below threshold\n",
        "                if match[\"similarity\"] < similarity_threshold:\n",
        "                    continue\n",
        "                new_entry = {\n",
        "                    \"term\": match[\"matched_go_name\"],      # replace Llama term\n",
        "                    \"go_id\": match[\"matched_go_id\"],       # new field\n",
        "                    \"relationship\": match[\"relationship\"], # official relationship\n",
        "                    \"namespace\": match[\"namespace\"],\n",
        "                    \"justification\": match[\"justification\"],\n",
        "                    # carry over references if you want:\n",
        "                    \"reference(s)\": gene_entry[\"go_data\"][0].get(\"reference(s)\", [])\n",
        "                }\n",
        "                new_go_data.append(new_entry)\n",
        "            gene_entry[\"go_data\"] = new_go_data\n",
        "    return llama_data\n",
        "\n",
        "# Create a  directory to store PROCESSED llama JSON outputs.\n",
        "processed_dir = os.path.join(os.getcwd(), \"processed_inferences\")\n",
        "if not os.path.exists(processed_dir):\n",
        "    os.makedirs(processed_dir)\n",
        "\n",
        "# Usage example:\n",
        "# 1. Load the Llama output JSON file and parse it\n",
        "llama_output_path = f\"./llama_inferences/llama_output_{doc_id}.json\"\n",
        "llama_data = parse_llama_output(llama_output_path)\n",
        "\n",
        "# 2. Match the Llama terms to official GO terms\n",
        "matched_terms = auto_match_go_terms(\n",
        "    llama_data, go_ids, go_names, go_embeddings, go_namespaces, go_relationships, sapbert_model, threshold=0.6\n",
        ")\n",
        "\n",
        "# 3. Replace llama terms with the official GO terms\n",
        "updated_data = replace_terms_with_go(llama_data, matched_terms)\n",
        "\n",
        "# 4. save the processed JSON output to a new file\n",
        "procesed_output_path = os.path.join(processed_dir, f\"processed_output_{doc_id}.json\")\n",
        "with open(procesed_output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(updated_data, f, indent=2)\n",
        "\n",
        "print(\"there are {} genes with matched GO terms.\".format(len(matched_terms)))\n",
        "for gene_id, matches in matched_terms.items():\n",
        "    print(f\"Gene: {gene_dict[gene_id].get_name_from_article()} ({gene_id})\")\n",
        "    for match in matches:\n",
        "        print(f\"  Llama Term: {match['llama_term']}\")\n",
        "        print(f\"  Matched GO Term: {match['matched_go_name']} ({match['matched_go_id']})\")\n",
        "        print(f\"  Similarity: {match['similarity']:.2f}\")\n",
        "        print(f\"  Relationship: {match['relationship']}\")\n",
        "        print(f\"  Namespace: {match['namespace']}\")\n",
        "        print(f\"  Justification: {match['justification']}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52hJV2NbJMzp"
      },
      "source": [
        "# 6. Evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DBtiTOtJgFO"
      },
      "source": [
        "6.1. Counting and Plotting Similarity Distributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "sPcTb_-UJLvq",
        "outputId": "4754b2f1-b823-432a-f485-1a874be690ee"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "# Suppose matched_terms is your dictionary of gene predictions (from auto_match_go_terms)\n",
        "# where each value is a list of dictionaries with a key 'similarity'\n",
        "similarity_scores = []\n",
        "for gene, matches in matched_terms.items():\n",
        "    for match in matches:\n",
        "        similarity_scores.append(match['similarity'])\n",
        "\n",
        "# Bin the similarity scores, e.g., rounded to one decimal place.\n",
        "binned_scores = [round(score, 1) for score in similarity_scores]\n",
        "score_counts = Counter(binned_scores)\n",
        "\n",
        "# Prepare data for the bar plot.\n",
        "bins = sorted(score_counts.keys())\n",
        "counts = [score_counts[b] for b in bins]\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(bins, counts, width=0.08, edgecolor='black')\n",
        "plt.xlabel('Cosine Similarity')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Distribution of GO Term Similarity Scores')\n",
        "plt.xticks(bins)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONKEXAOtZtjO"
      },
      "source": [
        "## 6.2. Scoring against NCBI Gene database\n",
        "\n",
        "Need to make a new scoring system: possibly True Positive (what we found), Nobel Positive (NP), Not Detected\n",
        "\n",
        "- for cases where we have Go terms that are alike like \"Wnt signaling pathway\" and \"canonical Wnt signaling pathway\", we can embed the terms and check if they are similar. If they are, then we can consider them as the same term. If not, then we can consider them as different terms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# term = \"Cul4A-RING E3 ubiquitin ligase complex\"\n",
        "# example_llama_term = \"ubiquitin ligase complex\"\n",
        "# def compute_semantic_similarity(term1, term2, model):\n",
        "#     \"\"\"\n",
        "#     Returns a cosine similarity score between two text strings, using\n",
        "#     a SentenceTransformer model.\n",
        "#     \"\"\"\n",
        "#     emb1 = model.encode(term1, convert_to_tensor=True)\n",
        "#     emb2 = model.encode(term2, convert_to_tensor=True)\n",
        "#     cos_sim = util.cos_sim(emb1, emb2)\n",
        "#     return float(cos_sim[0][0])  # scalar\n",
        "\n",
        "# # Compute the semantic similarity between the Llama term and the official GO term\n",
        "# res = compute_semantic_similarity(example_llama_term, term, sapbert_model)\n",
        "# print(f\"Semantic similarity between '{example_llama_term}' and '{term}': {res:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The code below takes a bit of time due to:\n",
        "- api calls to retrieve the gene ontology terms from NCBI Gene database for each gene"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from Bio import Entrez\n",
        "import xml.etree.ElementTree as ET\n",
        "import time\n",
        "import requests\n",
        "\n",
        "###############################################################################\n",
        "# CONFIGURATION\n",
        "###############################################################################\n",
        "Entrez.email = \"your_email@example.com\"  # Use a valid email address\n",
        "\n",
        "SIMILARITY_THRESHOLD = 0.68\n",
        "MARGIN = 0.1  # The margin by which we'll allow a same-paper match to be \"close enough\"\n",
        "\n",
        "###############################################################################\n",
        "# 1) Utility: map from local \"namespace\" to NCBI's GO Category strings\n",
        "###############################################################################\n",
        "def map_namespace_to_ncbi_category(ns):\n",
        "    if ns == \"biological_process\":\n",
        "        return \"Process\"\n",
        "    elif ns == \"molecular_function\":\n",
        "        return \"Function\"\n",
        "    elif ns == \"cellular_component\":\n",
        "        return \"Component\"\n",
        "    return None\n",
        "\n",
        "###############################################################################\n",
        "# 2) Fetch the GO annotations from NCBI Gene for a given gene_id\n",
        "###############################################################################\n",
        "def fetch_gene_go_terms(gene_id):\n",
        "    \"\"\"\n",
        "    Fetch the NCBI Gene record (XML) for `gene_id` and parse out GO annotations.\n",
        "    Returns a dict of lists, keyed by: \"Function\", \"Process\", \"Component\".\n",
        "    \"\"\"\n",
        "    # Sleep to respect NCBI usage guidelines\n",
        "    time.sleep(0.3)\n",
        "\n",
        "    handle = Entrez.efetch(db=\"gene\", id=gene_id, retmode=\"xml\")\n",
        "    xml_data = handle.read()\n",
        "    handle.close()\n",
        "\n",
        "    root = ET.fromstring(xml_data)\n",
        "    go_annotations = {}\n",
        "\n",
        "    for gene_commentary in root.findall(\".//Gene-commentary\"):\n",
        "        heading_elem = gene_commentary.find(\"Gene-commentary_heading\")\n",
        "        if heading_elem is not None and heading_elem.text == \"GeneOntology\":\n",
        "            for category_block in gene_commentary.findall(\".//Gene-commentary_comment/Gene-commentary\"):\n",
        "                label_elem = category_block.find(\"Gene-commentary_label\")\n",
        "                if label_elem is None:\n",
        "                    continue\n",
        "                category_label = label_elem.text  # \"Function\", \"Process\", or \"Component\"\n",
        "\n",
        "                if category_label not in go_annotations:\n",
        "                    go_annotations[category_label] = []\n",
        "\n",
        "                inner_comment = category_block.find(\"Gene-commentary_comment\")\n",
        "                if inner_comment is None:\n",
        "                    continue\n",
        "\n",
        "                for go_term_block in inner_comment.findall(\"Gene-commentary\"):\n",
        "                    dbtag_db = go_term_block.find(\".//Dbtag_db\")\n",
        "                    if dbtag_db is not None and dbtag_db.text == \"GO\":\n",
        "                        # Parse the GO ID\n",
        "                        object_id_elem = go_term_block.find(\".//Object-id_id\")\n",
        "                        if object_id_elem is not None:\n",
        "                            numeric_id = object_id_elem.text\n",
        "                            padded_id = numeric_id.zfill(7)\n",
        "                            go_id = f\"GO:{padded_id}\"\n",
        "                        else:\n",
        "                            go_id = \"GO:unknown\"\n",
        "\n",
        "                        # Parse the GO term name\n",
        "                        anchor_elem = go_term_block.find(\".//Other-source_anchor\")\n",
        "                        go_term_name = anchor_elem.text if anchor_elem is not None else \"Unknown Term\"\n",
        "\n",
        "                        # Evidence code\n",
        "                        evidence_code = None\n",
        "                        post_text_elem = go_term_block.find(\".//Other-source_post-text\")\n",
        "                        if post_text_elem is not None:\n",
        "                            post_text_str = post_text_elem.text\n",
        "                            if post_text_str and \"evidence: \" in post_text_str:\n",
        "                                evidence_code = post_text_str.split(\"evidence:\")[-1].strip()\n",
        "                            else:\n",
        "                                evidence_code = post_text_str\n",
        "\n",
        "                        # PubMed IDs\n",
        "                        pubmed_ids = []\n",
        "                        refs_block = go_term_block.find(\"Gene-commentary_refs\")\n",
        "                        if refs_block is not None:\n",
        "                            for pub in refs_block.findall(\"Pub\"):\n",
        "                                pmid_elem = pub.find(\".//PubMedId\")\n",
        "                                if pmid_elem is not None:\n",
        "                                    pubmed_ids.append(pmid_elem.text)\n",
        "\n",
        "                        go_annotations[category_label].append({\n",
        "                            \"go_id\": go_id,\n",
        "                            \"term\": go_term_name,\n",
        "                            \"evidence\": evidence_code,\n",
        "                            \"pubmed_ids\": pubmed_ids\n",
        "                        })\n",
        "\n",
        "    return go_annotations\n",
        "\n",
        "###############################################################################\n",
        "# 3) Utility: compute cosine similarity using Sentence-BERT\n",
        "###############################################################################\n",
        "def compute_semantic_similarity(term1, term2, model):\n",
        "    emb1 = model.encode(term1, convert_to_tensor=True)\n",
        "    emb2 = model.encode(term2, convert_to_tensor=True)\n",
        "    cos_sim = util.cos_sim(emb1, emb2)\n",
        "    return float(cos_sim[0][0])\n",
        "\n",
        "###############################################################################\n",
        "# 4) Utility: convert a PMCID to PMID using NCBI E-utilities\n",
        "###############################################################################\n",
        "pmc_cache = {} # Cache for PMCID to PMID conversion\n",
        "\n",
        "def pmcid_to_pmid(pmcid):\n",
        "    \"\"\"\n",
        "    Convert a PMCID (e.g. 'PMC123456') to a numeric PMID string using NCBI E-utilities.\n",
        "    Returns None if not found or conversion fails.\n",
        "    \"\"\"\n",
        "    # cache since we dont want to hit the same PMCID multiple times\n",
        "    if pmcid in pmc_cache:\n",
        "        return pmc_cache[pmcid]\n",
        "    \n",
        "    base = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/\"\n",
        "    url = base + f\"esummary.fcgi?db=pmc&id={pmcid[3:]}&retmode=xml\"\n",
        "    # Note pmcid[3:] strips \"PMC\" prefix if we pass \"PMC123456\" to the 'id=' param\n",
        "\n",
        "    resp = requests.get(url)\n",
        "    if resp.status_code != 200:\n",
        "        return None\n",
        "\n",
        "    root = ET.fromstring(resp.text)\n",
        "\n",
        "    for item in root.findall(\".//Item\"):\n",
        "        if item.get(\"Name\") == \"pmid\":\n",
        "            pmid = item.text\n",
        "            pmc_cache[pmcid] = pmid\n",
        "            return pmid\n",
        "\n",
        "    return None\n",
        "\n",
        "def convert_local_pmcids_to_pmids(local_data):\n",
        "    for gene_entry in local_data:\n",
        "        for local_ann in gene_entry.get(\"go_data\", []):\n",
        "            refs = local_ann.get(\"reference(s)\", [])\n",
        "            new_refs = []\n",
        "            for r in refs:\n",
        "                # If r starts with 'PMC', attempt to convert\n",
        "                if r.startswith(\"PMC\"):\n",
        "                    time.sleep(0.3)  # Respect NCBI usage guidelines\n",
        "                    pmid = pmcid_to_pmid(r)\n",
        "                    if pmid:\n",
        "                        new_refs.append(pmid)\n",
        "                    else:\n",
        "                        # Conversion failed or none found, fallback\n",
        "                        new_refs.append(r)\n",
        "                else:\n",
        "                    new_refs.append(r)\n",
        "            local_ann[\"reference(s)\"] = new_refs\n",
        "\n",
        "###############################################################################\n",
        "# 5) Main comparison & classification logic with tie-break margin\n",
        "###############################################################################\n",
        "def compare_json_vs_ncbi(json_path, model):\n",
        "    \"\"\"\n",
        "    For each local annotation (term + references), we:\n",
        "      1) Gather all possible NCBI annotations in the same GO category\n",
        "      2) Find best match overall & best match among same-paper (i.e., shared PMIDs)\n",
        "      3) If best_same_score >= best_overall_score - MARGIN, prefer the same-paper match\n",
        "      4) Classify that chosen match as TP if it shares references, else DCU (if >= threshold),\n",
        "         or NP if below threshold.\n",
        "    \"\"\"\n",
        "    with open(json_path, \"r\") as f:\n",
        "        local_data = json.load(f)\n",
        "\n",
        "    # Convert PMCIDs in local_data to numeric PMIDs since NCBI uses PMIDs even thorugh GO annotations are curated from PMC\n",
        "    convert_local_pmcids_to_pmids(local_data)\n",
        "\n",
        "    all_comparisons = []\n",
        "\n",
        "    for gene_entry in local_data:\n",
        "        gene_name = gene_entry[\"gene\"]\n",
        "        gene_id = gene_entry[\"geneID\"]\n",
        "        local_go_data = gene_entry.get(\"go_data\", [])\n",
        "\n",
        "        print(f\"\\n=== Checking Gene: {gene_name} (ID={gene_id}) ===\")\n",
        "\n",
        "        ncbi_annotations = fetch_gene_go_terms(gene_id)\n",
        "\n",
        "        # We'll keep track of official GO annotations (for ND detection)\n",
        "        official_by_pmid = set()\n",
        "        for category_label, ann_list in ncbi_annotations.items():\n",
        "            for ann in ann_list:\n",
        "                for pmid in ann[\"pubmed_ids\"]:\n",
        "                    official_by_pmid.add((category_label, ann[\"term\"], pmid))\n",
        "\n",
        "        matched_officials = set()\n",
        "        comparisons_this_gene = []\n",
        "\n",
        "        # Per-gene counters\n",
        "        count_tp = 0\n",
        "        count_np = 0\n",
        "        count_dcu = 0\n",
        "\n",
        "        #\n",
        "        # 1) CLASSIFY EACH LOCAL ANNOTATION (TP, NP, DCU)\n",
        "        #\n",
        "        for local_ann in local_go_data:\n",
        "            local_term = local_ann[\"term\"]\n",
        "            local_refs = set(local_ann.get(\"reference(s)\", []))\n",
        "            local_ns = local_ann.get(\"namespace\", None)\n",
        "            target_category = map_namespace_to_ncbi_category(local_ns)\n",
        "\n",
        "            classification = None\n",
        "            chosen_match_info = None\n",
        "            chosen_score = -1.0\n",
        "\n",
        "            best_score_all = -1.0\n",
        "            best_info_all = None\n",
        "            best_score_same = -1.0\n",
        "            best_info_same = None\n",
        "\n",
        "            if target_category and target_category in ncbi_annotations:\n",
        "                possible_anns = ncbi_annotations[target_category]\n",
        "\n",
        "                # (A) Find best match overall\n",
        "                for ann in possible_anns:\n",
        "                    sc = compute_semantic_similarity(local_term, ann[\"term\"], model)\n",
        "                    if sc > best_score_all:\n",
        "                        best_score_all = sc\n",
        "                        best_info_all = ann\n",
        "\n",
        "                # (B) Find best match among same-paper\n",
        "                same_paper_anns = [\n",
        "                    ann for ann in possible_anns\n",
        "                    if set(ann[\"pubmed_ids\"]).intersection(local_refs)\n",
        "                ]\n",
        "                for ann in same_paper_anns:\n",
        "                    sc = compute_semantic_similarity(local_term, ann[\"term\"], model)\n",
        "                    if sc > best_score_same:\n",
        "                        best_score_same = sc\n",
        "                        best_info_same = ann\n",
        "\n",
        "                # (C) Tie-break\n",
        "                if best_score_same >= 0:\n",
        "                    # There's at least one same-paper annotation\n",
        "                    if best_score_same >= best_score_all - MARGIN:\n",
        "                        chosen_score = best_score_same\n",
        "                        chosen_match_info = best_info_same\n",
        "                    else:\n",
        "                        chosen_score = best_score_all\n",
        "                        chosen_match_info = best_info_all\n",
        "                else:\n",
        "                    chosen_score = best_score_all\n",
        "                    chosen_match_info = best_info_all\n",
        "\n",
        "                # (D) Classify\n",
        "                if chosen_score >= SIMILARITY_THRESHOLD and chosen_match_info is not None:\n",
        "                    overlap = set(chosen_match_info[\"pubmed_ids\"]).intersection(local_refs)\n",
        "                    if overlap:\n",
        "                        classification = \"TP\"\n",
        "                        count_tp += 1\n",
        "                        # Mark the official annotation as matched\n",
        "                        for pmid in chosen_match_info[\"pubmed_ids\"]:\n",
        "                            if pmid in local_refs:\n",
        "                                matched_officials.add((target_category, chosen_match_info[\"term\"], pmid))\n",
        "                    else:\n",
        "                        classification = \"DCU\"\n",
        "                        count_dcu += 1\n",
        "                else:\n",
        "                    classification = \"NP\"\n",
        "                    count_np += 1\n",
        "            else:\n",
        "                # No recognized category => NP\n",
        "                classification = \"NP\"\n",
        "                count_np += 1\n",
        "\n",
        "            rec = {\n",
        "                \"gene\": gene_name,\n",
        "                \"geneID\": gene_id,\n",
        "                \"local_term\": local_term,\n",
        "                \"namespace\": local_ns,\n",
        "                \"references_used\": list(local_refs),\n",
        "                \"classification\": classification,\n",
        "                \"best_score\": chosen_score,\n",
        "            }\n",
        "            if chosen_match_info:\n",
        "                rec[\"best_ncbi_match\"] = chosen_match_info[\"term\"]\n",
        "                rec[\"best_ncbi_go_id\"] = chosen_match_info[\"go_id\"]\n",
        "                rec[\"best_ncbi_pubmed_ids\"] = chosen_match_info[\"pubmed_ids\"]\n",
        "            else:\n",
        "                rec[\"best_ncbi_match\"] = None\n",
        "                rec[\"best_ncbi_go_id\"] = None\n",
        "                rec[\"best_ncbi_pubmed_ids\"] = []\n",
        "\n",
        "            comparisons_this_gene.append(rec)\n",
        "\n",
        "        #\n",
        "        # 2) DETECT ND (NOT DETECTED) AND STORE AS ADDITIONAL RECORDS\n",
        "        #\n",
        "        # ND means: official NCBI annotation referencing the local paper(s),\n",
        "        # but never matched as a TP above.\n",
        "        #\n",
        "        undetected = official_by_pmid - matched_officials\n",
        "\n",
        "        # The local paper set is all refs mentioned in local_go_data\n",
        "        all_local_pmids_for_gene = set()\n",
        "        for ann in local_go_data:\n",
        "            all_local_pmids_for_gene |= set(ann.get(\"reference(s)\", []))\n",
        "\n",
        "        actual_nd = []\n",
        "        for (cat_label, term_text, pmid) in undetected:\n",
        "            if pmid in all_local_pmids_for_gene:\n",
        "                actual_nd.append((cat_label, term_text, pmid))\n",
        "\n",
        "        count_nd = len(actual_nd)\n",
        "\n",
        "        # Storing ND in comparisons_this_gene\n",
        "        # For each official annotation that is ND, we add a new record\n",
        "        for (cat_label, ncbi_term, pmid) in actual_nd:\n",
        "            rec = {\n",
        "                \"gene\": gene_name,\n",
        "                \"geneID\": gene_id,\n",
        "                \"local_term\": None,  # No local annotation matched\n",
        "                \"namespace\": cat_label,\n",
        "                \"references_used\": [pmid],  # or empty if you prefer\n",
        "                \"classification\": \"ND\",\n",
        "                \"best_score\": None,\n",
        "                # We might store the official annotation in 'best_ncbi_match'\n",
        "                \"best_ncbi_match\": ncbi_term,\n",
        "                \"best_ncbi_go_id\": None,  # We didn't parse that here, but could\n",
        "                \"best_ncbi_pubmed_ids\": [pmid],\n",
        "            }\n",
        "            comparisons_this_gene.append(rec)\n",
        "\n",
        "        #\n",
        "        # 3) PRINT RESULTS\n",
        "        #\n",
        "        print(\"-- NDs --\")\n",
        "        for nd_item in actual_nd:\n",
        "            print(f\"Category={nd_item[0]}, Term='{nd_item[1]}', PMID={nd_item[2]}\")\n",
        "\n",
        "        # Summaries\n",
        "        tps_for_gene = [x for x in comparisons_this_gene if x[\"classification\"] == \"TP\"]\n",
        "        nps_for_gene = [x for x in comparisons_this_gene if x[\"classification\"] == \"NP\"]\n",
        "        dcus_for_gene = [x for x in comparisons_this_gene if x[\"classification\"] == \"DCU\"]\n",
        "        nds_for_gene = [x for x in comparisons_this_gene if x[\"classification\"] == \"ND\"]\n",
        "\n",
        "        print(\"\\n-- TPs --\")\n",
        "        for item in tps_for_gene:\n",
        "            print(f\"LocalTerm='{item['local_term']}' | BestNCBI='{item['best_ncbi_match']}' \"\n",
        "                  f\"| Score={item['best_score']:.2f} | PMIDs={item['references_used']}\")\n",
        "\n",
        "        print(\"\\n-- NPs --\")\n",
        "        for item in nps_for_gene:\n",
        "            print(f\"LocalTerm='{item['local_term']}' | Score={item['best_score']}\"\n",
        "                  f\"| PMIDs={item['references_used']}\")\n",
        "\n",
        "        print(\"\\n-- DCUs --\")\n",
        "        for item in dcus_for_gene:\n",
        "            print(f\"LocalTerm='{item['local_term']}' | BestNCBI='{item['best_ncbi_match']}' \"\n",
        "                  f\"(diff. references) | Score={item['best_score']} | PMIDs={item['references_used']}\")\n",
        "\n",
        "        print(\"\\n-- ND --\")\n",
        "        for item in nds_for_gene:\n",
        "            print(f\"NCBITerm='{item['best_ncbi_match']}' | PMID={item['best_ncbi_pubmed_ids']}\")\n",
        "        \n",
        "        print(f\"\\n== Per-gene Summary for {gene_name} ({gene_id}) ==\")\n",
        "        print(f\"TP = {count_tp}, NP = {count_np}, DCU = {count_dcu}, ND = {count_nd}\")\n",
        "        print(\"--------------------------------------------------------\")\n",
        "\n",
        "        all_comparisons.extend(comparisons_this_gene)\n",
        "\n",
        "    return all_comparisons\n",
        "\n",
        "###############################################################################\n",
        "# 6) Example usage\n",
        "###############################################################################\n",
        "json_file_path = f\"./processed_inferences/processed_output_{doc_id}.json\"\n",
        "\n",
        "try:\n",
        "    comparison_results = compare_json_vs_ncbi(json_file_path, sapbert_model)\n",
        "except requests.HTTPError as e:\n",
        "    print(f\"HTTPError: {e.code} - {e.reason}\")\n",
        "    print(\"Please check the gene ID or ensure that the NCBI API is accessible.\")\n",
        "\n",
        "# Now each item in comparison_results has classification in {TP, NP, DCU, ND}\n",
        "\n",
        "# You can also sum ND from the final list if you want a global ND count\n",
        "tp_global = sum(1 for r in comparison_results if r[\"classification\"] == \"TP\")\n",
        "np_global = sum(1 for r in comparison_results if r[\"classification\"] == \"NP\")\n",
        "dcu_global = sum(1 for r in comparison_results if r[\"classification\"] == \"DCU\")\n",
        "nd_global = sum(1 for r in comparison_results if r[\"classification\"] == \"ND\")\n",
        "\n",
        "print(\"\\n=== Global Summary Across All Genes ===\")\n",
        "print(f\"Total entries: {len(comparison_results)}\")\n",
        "print(f\"TP = {tp_global}, NP = {np_global}, DCU = {dcu_global}, ND = {nd_global}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Will put TP, ND, DCU and NP in a excel file in the output folder\n",
        "change the sheet_name to the name of the file you want to save it as in the excel. After that, open excel and copy the sheet to the main sheet. Then delete the other sheet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from openpyxl import load_workbook\n",
        "from collections import defaultdict\n",
        "\n",
        "###############################################################################\n",
        "# 1) Aggregate classification_counts from comparison_results\n",
        "###############################################################################\n",
        "classification_counts = defaultdict(lambda: {\"TP\": 0, \"NP\": 0, \"DCU\": 0, \"ND\": 0})\n",
        "\n",
        "for row in comparison_results:\n",
        "    gene_id = row[\"geneID\"]\n",
        "    gene_name = row[\"gene\"]\n",
        "    classification = row[\"classification\"]\n",
        "    \n",
        "    # For each PMID in references_used, increment the classification count\n",
        "    for pmid in row[\"references_used\"]:\n",
        "        key = (gene_id, gene_name, pmid)\n",
        "        classification_counts[key][classification] += 1\n",
        "\n",
        "records_for_df = []\n",
        "for (gid, gname, pmid), counts in classification_counts.items():\n",
        "    records_for_df.append({\n",
        "        \"geneID\": gid,\n",
        "        \"gene\": gname,\n",
        "        \"pmid\": pmid,\n",
        "        \"TP\": counts[\"TP\"],\n",
        "        \"ND\": counts[\"ND\"],\n",
        "        \"NP\": counts[\"NP\"],\n",
        "        \"DCU\": counts[\"DCU\"]\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(\n",
        "    records_for_df,\n",
        "    columns=[\"geneID\", \"gene\", \"pmid\", \"TP\", \"ND\", \"NP\", \"DCU\"]\n",
        ")\n",
        "\n",
        "###############################################################################\n",
        "# 2) Write to Excel, appending a NEW SHEET for each paper\n",
        "###############################################################################\n",
        "output_path = r\"C:\\Users\\aivan\\OneDrive\\Documents\\Evaluation.xlsx\"\n",
        "\n",
        "# You can change this to something unique for each paper you analyze.\n",
        "sheet_name = doc_id\n",
        "\n",
        "# If the file already exists, open in append mode. Otherwise, create a new file.\n",
        "mode = \"a\" if os.path.exists(output_path) else \"w\"\n",
        "\n",
        "if mode == \"w\":\n",
        "    # Create a new file and write data\n",
        "    df.to_excel(output_path, sheet_name=sheet_name, index=False)\n",
        "else:\n",
        "    # If the file already exists, append a new sheet\n",
        "    with pd.ExcelWriter(output_path, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"new\") as writer:\n",
        "        df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "\n",
        "print(f\"Finished! Data written to sheet '{sheet_name}' in file: {output_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "6oaKSo6iXGOc"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "BIOIN311C1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "097046dc7c4f46f5866068c82b706aca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1675d70c8a5e426691d0af5e6ba333f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_784d7bf8c3be48b8ad5a3b6e6954690f",
              "IPY_MODEL_730fe49f91204e2cbd3b58d24442be0a",
              "IPY_MODEL_792eb1f8daf34e2590fda2f60e3ff684"
            ],
            "layout": "IPY_MODEL_3e0f9cdf58ef4af1a0b16f9795747dfc"
          }
        },
        "1845ddb7ff634d969fa2538209fc4e0a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b8c25318a2b4b64bab3496083679c85": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2443ed122977428c98248537123b674b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7dcd748d0944da09948f4372366e8a8",
            "placeholder": "​",
            "style": "IPY_MODEL_466f8ef6ba644d31a8586abaf9830448",
            "value": " 438M/438M [00:01&lt;00:00, 251MB/s]"
          }
        },
        "3117723c389b4e47a97d6e582078e5c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32ef3e232304493d8b7e129c679f4f6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1c01cfdd57e40e7bc4de9baf81d9f45",
            "placeholder": "​",
            "style": "IPY_MODEL_82a3774cc5cd4acfb1822d9cb74d6f45",
            "value": " 112/112 [00:00&lt;00:00, 9.27kB/s]"
          }
        },
        "331dbfdb6d7849c6a7b6d43bd33a7325": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8eb65674477e477091f2501704df7eb8",
            "placeholder": "​",
            "style": "IPY_MODEL_6d29b58c64cc4f869d6944699149a60e",
            "value": "model.safetensors: 100%"
          }
        },
        "39794838a2164151a5edf298a63f8147": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e0f9cdf58ef4af1a0b16f9795747dfc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "466f8ef6ba644d31a8586abaf9830448": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47571c7570f14ab58f96e5d30129da1b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a743c94312c4b5db25087a747f6b879": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea731973ab9c44caa479fb7934fd3b4f",
            "max": 198,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_097046dc7c4f46f5866068c82b706aca",
            "value": 198
          }
        },
        "4af857d8e5a94c278ae0fb3d7e092ac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53bb7f0fbad34a818e266d0ea44ffaf1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54a0cadcc9ef406db05d36b690d7891c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c939f017049643b18d5142514937af73",
            "max": 437955508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6c463c9a4bef4b5194113acf7ced731e",
            "value": 437955508
          }
        },
        "59dc6c4216cb4c5aad8c3764cf3d3f6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc7573c531c84e61999e2161710173f3",
            "placeholder": "​",
            "style": "IPY_MODEL_9775c0cd37bc43dcb7953f8b15343332",
            "value": " 198/198 [00:00&lt;00:00, 14.3kB/s]"
          }
        },
        "618fd6a5462e4c5296b560f888b5d638": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_331dbfdb6d7849c6a7b6d43bd33a7325",
              "IPY_MODEL_54a0cadcc9ef406db05d36b690d7891c",
              "IPY_MODEL_2443ed122977428c98248537123b674b"
            ],
            "layout": "IPY_MODEL_c3911d8aca764dd38fad4c1dded8198f"
          }
        },
        "61de99be2c2e4afe90ff06e3bb30a2b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ac927f5e2a2453d9aae4b5c474cf96d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7593152124e04332b709dd30ec87c5a5",
              "IPY_MODEL_4a743c94312c4b5db25087a747f6b879",
              "IPY_MODEL_59dc6c4216cb4c5aad8c3764cf3d3f6d"
            ],
            "layout": "IPY_MODEL_3117723c389b4e47a97d6e582078e5c9"
          }
        },
        "6c463c9a4bef4b5194113acf7ced731e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d29b58c64cc4f869d6944699149a60e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "730fe49f91204e2cbd3b58d24442be0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d598fdb3d94a4095ba5a950cef321f1b",
            "max": 226150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39794838a2164151a5edf298a63f8147",
            "value": 226150
          }
        },
        "7593152124e04332b709dd30ec87c5a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6b5cf46fbeb41adb8da935949b808c1",
            "placeholder": "​",
            "style": "IPY_MODEL_d4b8ff5330d14128ba304020f7fe8412",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "769b37c671334690b6a7e5ba9059343e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bdf351e0ccbc4aa18e168f593d1659cf",
              "IPY_MODEL_8901a8884437441c934c53a98a1dac06",
              "IPY_MODEL_32ef3e232304493d8b7e129c679f4f6f"
            ],
            "layout": "IPY_MODEL_77472246b6b0497fbe67b8a3529040e5"
          }
        },
        "77472246b6b0497fbe67b8a3529040e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "784d7bf8c3be48b8ad5a3b6e6954690f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1845ddb7ff634d969fa2538209fc4e0a",
            "placeholder": "​",
            "style": "IPY_MODEL_9b03af45365c42419bb39779b82be47c",
            "value": "vocab.txt: 100%"
          }
        },
        "792eb1f8daf34e2590fda2f60e3ff684": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7eaa149a903445db37dfdf719e14f9e",
            "placeholder": "​",
            "style": "IPY_MODEL_4af857d8e5a94c278ae0fb3d7e092ac5",
            "value": " 226k/226k [00:00&lt;00:00, 1.03MB/s]"
          }
        },
        "7d97b347b7cb40df81041035931d7f27": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53bb7f0fbad34a818e266d0ea44ffaf1",
            "placeholder": "​",
            "style": "IPY_MODEL_bc435a026437452bb820c14d1ce5d3ee",
            "value": "config.json: 100%"
          }
        },
        "8039b35f8f654a5e93ab69a0d1d8f3ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "82a3774cc5cd4acfb1822d9cb74d6f45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "873ea6832a0447a19938fe764cb7ac58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8901a8884437441c934c53a98a1dac06": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b483173c5fa74a72bb0a88206d3206a3",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8039b35f8f654a5e93ab69a0d1d8f3ea",
            "value": 112
          }
        },
        "8eb65674477e477091f2501704df7eb8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9775c0cd37bc43dcb7953f8b15343332": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b03af45365c42419bb39779b82be47c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1c01cfdd57e40e7bc4de9baf81d9f45": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b483173c5fa74a72bb0a88206d3206a3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b85f6bb59d024282b5552ff665da4548": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47571c7570f14ab58f96e5d30129da1b",
            "max": 462,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec42f776af1b48a982636f0c122ab7e6",
            "value": 462
          }
        },
        "bc435a026437452bb820c14d1ce5d3ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bdf351e0ccbc4aa18e168f593d1659cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61de99be2c2e4afe90ff06e3bb30a2b7",
            "placeholder": "​",
            "style": "IPY_MODEL_873ea6832a0447a19938fe764cb7ac58",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "c3911d8aca764dd38fad4c1dded8198f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6b5cf46fbeb41adb8da935949b808c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c939f017049643b18d5142514937af73": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc7573c531c84e61999e2161710173f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4b8ff5330d14128ba304020f7fe8412": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d598fdb3d94a4095ba5a950cef321f1b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de6e3ef0670042378384c41ecd695f1a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4718c03421b41a2a665c26293acd697": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d97b347b7cb40df81041035931d7f27",
              "IPY_MODEL_b85f6bb59d024282b5552ff665da4548",
              "IPY_MODEL_f1219528a46a4a8e94bd1c8de9e6e16a"
            ],
            "layout": "IPY_MODEL_1b8c25318a2b4b64bab3496083679c85"
          }
        },
        "e7eaa149a903445db37dfdf719e14f9e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea731973ab9c44caa479fb7934fd3b4f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec42f776af1b48a982636f0c122ab7e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec7200455fa34863bec2ae60f9f4aad5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1219528a46a4a8e94bd1c8de9e6e16a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de6e3ef0670042378384c41ecd695f1a",
            "placeholder": "​",
            "style": "IPY_MODEL_ec7200455fa34863bec2ae60f9f4aad5",
            "value": " 462/462 [00:00&lt;00:00, 40.9kB/s]"
          }
        },
        "f7dcd748d0944da09948f4372366e8a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
