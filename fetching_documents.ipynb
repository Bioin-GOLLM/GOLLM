{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2G7k3ZnFqp6J",
        "outputId": "c57f4f42-d167-4560-8aa3-dfb09f63cfee"
      },
      "outputs": [],
      "source": [
        "import gzip\n",
        "import os\n",
        "import requests\n",
        "import time\n",
        "\n",
        "def filter_matching_pmids(gene_gz, mutation_gz, output_file):\n",
        "    \"\"\"\n",
        "    Filters PMIDs that are present in both gene2pubtator3 and mutation2pubtator3 files.\n",
        "\n",
        "    Args:\n",
        "        gene_gz (str): Path to the gene2pubtator3.gz file.\n",
        "        mutation_gz (str): Path to the mutation2pubtator3.gz file.\n",
        "        output_file (str): Path to the output file for matched PMIDs.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Read gene2pubtator3 PMIDs\n",
        "        with gzip.open(gene_gz, 'rt', encoding='utf-8') as gene_file:\n",
        "            gene_pmids = set(line.split('\\t')[0] for line in gene_file)\n",
        "\n",
        "        # Read mutation2pubtator3 PMIDs and find intersection\n",
        "        matching_pmids = set()\n",
        "        with gzip.open(mutation_gz, 'rt', encoding='utf-8') as mutation_file:\n",
        "            for line in mutation_file:\n",
        "                pmid = line.split('\\t')[0]\n",
        "                if pmid in gene_pmids:\n",
        "                    matching_pmids.add(pmid)\n",
        "\n",
        "        # Write matching PMIDs to output file\n",
        "        with open(output_file, 'w', encoding='utf-8') as out_file:\n",
        "            for pmid in matching_pmids:\n",
        "                out_file.write(f\"{pmid}\\n\")\n",
        "\n",
        "        print(f\"Successfully wrote {len(matching_pmids)} matching PMIDs to {output_file}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error filtering PMIDs: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BlTiSM1imKU",
        "outputId": "95c03cfd-b6f3-449a-8962-a33079c83360"
      },
      "outputs": [],
      "source": [
        "import gzip\n",
        "import os\n",
        "import requests\n",
        "import time\n",
        "\n",
        "def fetch_articles(pmids_file, output_dir, email, api_key):\n",
        "    \"\"\"\n",
        "    Fetches article metadata and abstracts using the PubMed API for a list of PMIDs.\n",
        "\n",
        "    Args:\n",
        "        pmids_file (str): Path to the file containing PMIDs.\n",
        "        output_dir (str): Directory to save the fetched articles.\n",
        "        email (str): Email address for the PubMed API.\n",
        "        api_key (str): API key for the PubMed API.\n",
        "    \"\"\"\n",
        "    base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n",
        "    headers = {\"User-Agent\": email}\n",
        "    failure_log = \"failed_fetches.txt\"\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    try:\n",
        "        with open(pmids_file, 'r', encoding='utf-8') as file:\n",
        "            pmids = [line.strip() for line in file]\n",
        "\n",
        "        for i, pmid in enumerate(pmids):\n",
        "            final_output_path = os.path.join(output_dir, f\"{pmid}.txt\")\n",
        "            temp_output_path = os.path.join(output_dir, f\"{pmid}.tmp\")\n",
        "            if os.path.exists(final_output_path):\n",
        "                print(f\"PMID {pmid} already fetched. Skipping ({i+1}/{len(pmids)})\")\n",
        "                continue\n",
        "\n",
        "            params = {\n",
        "                \"db\": \"pubmed\",\n",
        "                \"id\": pmid,\n",
        "                \"rettype\": \"abstract\",\n",
        "                \"retmode\": \"text\",\n",
        "                \"api_key\": api_key\n",
        "            }\n",
        "            try:\n",
        "                response = requests.get(base_url, headers=headers, params=params)\n",
        "\n",
        "                if response.status_code == 200:\n",
        "                    with open(temp_output_path, 'w', encoding='utf-8') as temp_file:\n",
        "                        temp_file.write(response.text)\n",
        "                    os.rename(temp_output_path, final_output_path)\n",
        "                    print(f\"Fetched article for PMID {pmid} ({i+1}/{len(pmids)})\")\n",
        "                else:\n",
        "                    print(f\"Failed to fetch PMID {pmid}: {response.status_code}\")\n",
        "                    with open(failure_log, 'a', encoding='utf-8') as fail_file:\n",
        "                        fail_file.write(f\"{pmid}\\n\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error fetching PMID {pmid}: {e}\")\n",
        "                with open(failure_log, 'a', encoding='utf-8') as fail_file:\n",
        "                    fail_file.write(f\"{pmid}\\n\")\n",
        "\n",
        "            time.sleep(0.13)  # Reduced sleep time to increase request rate\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching articles: {e}\")\n",
        "\n",
        "def main():\n",
        "    # Paths to input files\n",
        "    gene_gz = \"./data/gene2pubtator3.gz\"\n",
        "    mutation_gz = \"./data/mutation2pubtator3.gz\"\n",
        "\n",
        "    # Path to output file for matching PMIDs\n",
        "    matching_pmids_file = \"./data/matching_pmids.txt\"\n",
        "\n",
        "    # Directory to save fetched articles\n",
        "    articles_dir = \"./data/fetched_articles\"\n",
        "\n",
        "    # PubMed API credentials\n",
        "    email = \"\"  # Replace with your email\n",
        "    api_key = \"\"  # Replace with your API key\n",
        "\n",
        "    # Filter and write matching PMIDs\n",
        "    #filter_matching_pmids(gene_gz, mutation_gz, matching_pmids_file)\n",
        "\n",
        "    # Fetch articles for matching PMIDs\n",
        "    fetch_articles(matching_pmids_file, articles_dir, email, api_key)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7jEpzqdiJyI"
      },
      "outputs": [],
      "source": [
        "import gzip\n",
        "import os\n",
        "import requests\n",
        "import time\n",
        "\n",
        "def fetch_articles(pmids_file, output_dir, email, api_key, failure_log_dir):\n",
        "    \"\"\"\n",
        "    Fetches article metadata and abstracts using the PubMed API for a list of PMIDs.\n",
        "\n",
        "    Args:\n",
        "        pmids_file (str): Path to the file containing PMIDs.\n",
        "        output_dir (str): Directory to save the fetched articles.\n",
        "        email (str): Email address for the PubMed API.\n",
        "        api_key (str): API key for the PubMed API.\n",
        "        failure_log_dir (str): Directory to save the failure logs.\n",
        "    \"\"\"\n",
        "    base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n",
        "    headers = {\"User-Agent\": email}\n",
        "    subset_name = os.path.splitext(os.path.basename(pmids_file))[0]\n",
        "    failure_log = os.path.join(failure_log_dir, f\"{subset_name}_failed_fetches.txt\")\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    if not os.path.exists(failure_log_dir):\n",
        "        os.makedirs(failure_log_dir)\n",
        "\n",
        "    try:\n",
        "        with open(pmids_file, 'r', encoding='utf-8') as file:\n",
        "            pmids = [line.strip() for line in file]\n",
        "\n",
        "        for i, pmid in enumerate(pmids):\n",
        "            final_output_path = os.path.join(output_dir, f\"{pmid}.txt\")\n",
        "            temp_output_path = os.path.join(output_dir, f\"{pmid}.tmp\")\n",
        "            if os.path.exists(final_output_path):\n",
        "                print(f\"PMID {pmid} already fetched. Skipping ({i+1}/{len(pmids)})\")\n",
        "                continue\n",
        "\n",
        "            params = {\n",
        "                \"db\": \"pubmed\",\n",
        "                \"id\": pmid,\n",
        "                \"rettype\": \"abstract\",\n",
        "                \"retmode\": \"text\",\n",
        "                \"api_key\": api_key\n",
        "            }\n",
        "            try:\n",
        "                response = requests.get(base_url, headers=headers, params=params)\n",
        "\n",
        "                if response.status_code == 200:\n",
        "                    with open(temp_output_path, 'w', encoding='utf-8') as temp_file:\n",
        "                        temp_file.write(response.text)\n",
        "                    os.rename(temp_output_path, final_output_path)\n",
        "                    # print(f\"Fetched article for PMID {pmid} ({i+1}/{len(pmids)})\")\n",
        "                else:\n",
        "                    print(f\"Failed to fetch PMID {pmid}: {response.status_code}\")\n",
        "                    with open(failure_log, 'a', encoding='utf-8') as fail_file:\n",
        "                        fail_file.write(f\"{pmid}\\n\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error fetching PMID {pmid}: {e}\")\n",
        "                with open(failure_log, 'a', encoding='utf-8') as fail_file:\n",
        "                    fail_file.write(f\"{pmid}\\n\")\n",
        "\n",
        "            time.sleep(0.1105)  # Reduced sleep time to increase request rate\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching articles: {e}\")\n",
        "\n",
        "def main():\n",
        "    # Directory containing subset files\n",
        "    subsets_dir = \"./data/matching_pmids_subsets\"\n",
        "    \n",
        "    # Directory to save fetched articles\n",
        "    fetched_articles_subsets_dir = \"./data/fetched_articles_subsets\"\n",
        "    \n",
        "    # Directory to save failure logs\n",
        "    failure_log_dir = \"./data/failed_fetches\"\n",
        "    \n",
        "    # PubMed API credentials\n",
        "    email = \"dolor@ualberta.ca\"  # Replace with your email\n",
        "    api_key = \"\"  # Replace with your API key\n",
        "\n",
        "    # Iterate over each subset file and fetch articles\n",
        "    for subset_file in os.listdir(subsets_dir):\n",
        "        print(f\"Processing subset file: {subset_file}\")\n",
        "        start_time = time.time()\n",
        "        if subset_file.endswith(\".txt\"):\n",
        "            subset_path = os.path.join(subsets_dir, subset_file)\n",
        "            subset_output_dir = os.path.join(fetched_articles_subsets_dir, os.path.splitext(subset_file)[0])\n",
        "            fetch_articles(subset_path, subset_output_dir, email, api_key, failure_log_dir)\n",
        "        print(f\"Finished processing subset file: {subset_file}. Took {time.time() - start_time:.2f} seconds\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "BIOIN311",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
