{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2G7k3ZnFqp6J",
        "outputId": "c57f4f42-d167-4560-8aa3-dfb09f63cfee"
      },
      "outputs": [],
      "source": [
        "import gzip\n",
        "import os\n",
        "import requests\n",
        "import time\n",
        "\n",
        "def filter_matching_pmids(gene_gz, mutation_gz, output_file):\n",
        "    \"\"\"\n",
        "    Filters PMIDs that are present in both gene2pubtator3 and mutation2pubtator3 files.\n",
        "\n",
        "    Args:\n",
        "        gene_gz (str): Path to the gene2pubtator3.gz file.\n",
        "        mutation_gz (str): Path to the mutation2pubtator3.gz file.\n",
        "        output_file (str): Path to the output file for matched PMIDs.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Read gene2pubtator3 PMIDs\n",
        "        with gzip.open(gene_gz, 'rt', encoding='utf-8') as gene_file:\n",
        "            gene_pmids = set(line.split('\\t')[0] for line in gene_file)\n",
        "\n",
        "        # Read mutation2pubtator3 PMIDs and find intersection\n",
        "        matching_pmids = set()\n",
        "        with gzip.open(mutation_gz, 'rt', encoding='utf-8') as mutation_file:\n",
        "            for line in mutation_file:\n",
        "                pmid = line.split('\\t')[0]\n",
        "                if pmid in gene_pmids:\n",
        "                    matching_pmids.add(pmid)\n",
        "\n",
        "        # Write matching PMIDs to output file\n",
        "        with open(output_file, 'w', encoding='utf-8') as out_file:\n",
        "            for pmid in matching_pmids:\n",
        "                out_file.write(f\"{pmid}\\n\")\n",
        "\n",
        "        print(f\"Successfully wrote {len(matching_pmids)} matching PMIDs to {output_file}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error filtering PMIDs: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BlTiSM1imKU",
        "outputId": "95c03cfd-b6f3-449a-8962-a33079c83360"
      },
      "outputs": [],
      "source": [
        "import gzip\n",
        "import os\n",
        "import requests\n",
        "import time\n",
        "\n",
        "def fetch_articles(pmids_file, output_dir, email, api_key):\n",
        "    \"\"\"\n",
        "    Fetches article metadata and abstracts using the PubMed API for a list of PMIDs.\n",
        "\n",
        "    Args:\n",
        "        pmids_file (str): Path to the file containing PMIDs.\n",
        "        output_dir (str): Directory to save the fetched articles.\n",
        "        email (str): Email address for the PubMed API.\n",
        "        api_key (str): API key for the PubMed API.\n",
        "    \"\"\"\n",
        "    base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n",
        "    headers = {\"User-Agent\": email}\n",
        "    failure_log = \"failed_fetches.txt\"\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    try:\n",
        "        with open(pmids_file, 'r', encoding='utf-8') as file:\n",
        "            pmids = [line.strip() for line in file]\n",
        "\n",
        "        for i, pmid in enumerate(pmids):\n",
        "            final_output_path = os.path.join(output_dir, f\"{pmid}.txt\")\n",
        "            temp_output_path = os.path.join(output_dir, f\"{pmid}.tmp\")\n",
        "            if os.path.exists(final_output_path):\n",
        "                print(f\"PMID {pmid} already fetched. Skipping ({i+1}/{len(pmids)})\")\n",
        "                continue\n",
        "\n",
        "            params = {\n",
        "                \"db\": \"pubmed\",\n",
        "                \"id\": pmid,\n",
        "                \"rettype\": \"abstract\",\n",
        "                \"retmode\": \"text\",\n",
        "                \"api_key\": api_key\n",
        "            }\n",
        "            try:\n",
        "                response = requests.get(base_url, headers=headers, params=params)\n",
        "\n",
        "                if response.status_code == 200:\n",
        "                    with open(temp_output_path, 'w', encoding='utf-8') as temp_file:\n",
        "                        temp_file.write(response.text)\n",
        "                    os.rename(temp_output_path, final_output_path)\n",
        "                    print(f\"Fetched article for PMID {pmid} ({i+1}/{len(pmids)})\")\n",
        "                else:\n",
        "                    print(f\"Failed to fetch PMID {pmid}: {response.status_code}\")\n",
        "                    with open(failure_log, 'a', encoding='utf-8') as fail_file:\n",
        "                        fail_file.write(f\"{pmid}\\n\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error fetching PMID {pmid}: {e}\")\n",
        "                with open(failure_log, 'a', encoding='utf-8') as fail_file:\n",
        "                    fail_file.write(f\"{pmid}\\n\")\n",
        "\n",
        "            time.sleep(0.13)  # Reduced sleep time to increase request rate\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching articles: {e}\")\n",
        "\n",
        "def main():\n",
        "    # Paths to input files\n",
        "    gene_gz = \"./data/gene2pubtator3.gz\"\n",
        "    mutation_gz = \"./data/mutation2pubtator3.gz\"\n",
        "\n",
        "    # Path to output file for matching PMIDs\n",
        "    matching_pmids_file = \"./data/matching_pmids.txt\"\n",
        "\n",
        "    # Directory to save fetched articles\n",
        "    articles_dir = \"./data/fetched_articles\"\n",
        "\n",
        "    # PubMed API credentials\n",
        "    email = \"\"  # Replace with your email\n",
        "    api_key = \"\"  # Replace with your API key\n",
        "\n",
        "    # Filter and write matching PMIDs\n",
        "    #filter_matching_pmids(gene_gz, mutation_gz, matching_pmids_file)\n",
        "\n",
        "    # Fetch articles for matching PMIDs\n",
        "    fetch_articles(matching_pmids_file, articles_dir, email, api_key)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7jEpzqdiJyI"
      },
      "outputs": [],
      "source": [
        "import gzip\n",
        "import os\n",
        "import requests\n",
        "import time\n",
        "\n",
        "def fetch_articles(pmids_file, output_dir, email, api_key, failure_log_dir):\n",
        "    \"\"\"\n",
        "    Fetches article metadata and abstracts using the PubMed API for a list of PMIDs.\n",
        "\n",
        "    Args:\n",
        "        pmids_file (str): Path to the file containing PMIDs.\n",
        "        output_dir (str): Directory to save the fetched articles.\n",
        "        email (str): Email address for the PubMed API.\n",
        "        api_key (str): API key for the PubMed API.\n",
        "        failure_log_dir (str): Directory to save the failure logs.\n",
        "    \"\"\"\n",
        "    base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi\"\n",
        "    headers = {\"User-Agent\": email}\n",
        "    subset_name = os.path.splitext(os.path.basename(pmids_file))[0]\n",
        "    failure_log = os.path.join(failure_log_dir, f\"{subset_name}_failed_fetches.txt\")\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    if not os.path.exists(failure_log_dir):\n",
        "        os.makedirs(failure_log_dir)\n",
        "\n",
        "    try:\n",
        "        with open(pmids_file, 'r', encoding='utf-8') as file:\n",
        "            pmids = [line.strip() for line in file]\n",
        "\n",
        "        for i, pmid in enumerate(pmids):\n",
        "            final_output_path = os.path.join(output_dir, f\"{pmid}.txt\")\n",
        "            temp_output_path = os.path.join(output_dir, f\"{pmid}.tmp\")\n",
        "            if os.path.exists(final_output_path):\n",
        "                print(f\"PMID {pmid} already fetched. Skipping ({i+1}/{len(pmids)})\")\n",
        "                continue\n",
        "\n",
        "            # https://www.ncbi.nlm.nih.gov/books/NBK25499/table/chapter4.T._valid_values_of__retmode_and/?report=objectonly\n",
        "            params = {\n",
        "                \"db\": \"pubmed\",\n",
        "                \"id\": pmid,\n",
        "                \"rettype\": \"abstract\",\n",
        "                \"retmode\": \"text\",\n",
        "                \"api_key\": api_key\n",
        "            }\n",
        "            try:\n",
        "                response = requests.get(base_url, headers=headers, params=params)\n",
        "\n",
        "                if response.status_code == 200:\n",
        "                    with open(temp_output_path, 'w', encoding='utf-8') as temp_file:\n",
        "                        temp_file.write(response.text)\n",
        "                    os.rename(temp_output_path, final_output_path)\n",
        "                    # print(f\"Fetched article for PMID {pmid} ({i+1}/{len(pmids)})\")\n",
        "                else:\n",
        "                    print(f\"Failed to fetch PMID {pmid}: {response.status_code}\")\n",
        "                    with open(failure_log, 'a', encoding='utf-8') as fail_file:\n",
        "                        fail_file.write(f\"{pmid}\\n\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error fetching PMID {pmid}: {e}\")\n",
        "                with open(failure_log, 'a', encoding='utf-8') as fail_file:\n",
        "                    fail_file.write(f\"{pmid}\\n\")\n",
        "\n",
        "            time.sleep(0.1105)  # Reduced sleep time to increase request rate\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching articles: {e}\")\n",
        "\n",
        "def main():\n",
        "    # Directory containing subset files\n",
        "    subsets_dir = \"./data/matching_pmids_subsets\"\n",
        "    \n",
        "    # Directory to save fetched articles\n",
        "    fetched_articles_subsets_dir = \"./data/fetched_articles_subsets\"\n",
        "    \n",
        "    # Directory to save failure logs\n",
        "    failure_log_dir = \"./data/failed_fetches\"\n",
        "    \n",
        "    # PubMed API credentials\n",
        "    email = \"\"  # Replace with your email\n",
        "    api_key = \"\"  # Replace with your API key\n",
        "\n",
        "    # Iterate over each subset file and fetch articles\n",
        "    for subset_file in os.listdir(subsets_dir):\n",
        "        print(f\"Processing subset file: {subset_file}\")\n",
        "        start_time = time.time()\n",
        "        if subset_file.endswith(\".txt\"):\n",
        "            subset_path = os.path.join(subsets_dir, subset_file)\n",
        "            subset_output_dir = os.path.join(fetched_articles_subsets_dir, os.path.splitext(subset_file)[0])\n",
        "            fetch_articles(subset_path, subset_output_dir, email, api_key, failure_log_dir)\n",
        "        print(f\"Finished processing subset file: {subset_file}. Took {time.time() - start_time:.2f} seconds\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fetch full-text articles in BioC format from PMC OA. \n",
        "The reason why I didn't use entrez is because the full-text articles fetched from it is in JATS XML which Pubtator3/AIONER can't process.I used BioC API for PMC Open Access instead [link here](https://www.ncbi.nlm.nih.gov/research/bionlp/APIs/BioC-PMC/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📂 Processing subset file: subset_1.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading subset_1:   1%|          | 74/8022 [01:19<2:23:05,  1.08s/article]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 83\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Finished processing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubset_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 83\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[7], line 78\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     75\u001b[0m     subset_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(subsets_dir, subset_file)\n\u001b[0;32m     76\u001b[0m     subset_output_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(fetched_articles_subsets_dir, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(subset_file)[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m---> 78\u001b[0m     \u001b[43mfetch_pmc_articles\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubset_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubset_output_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfailure_log_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Finished processing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubset_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[1;32mIn[7], line 40\u001b[0m, in \u001b[0;36mfetch_pmc_articles\u001b[1;34m(pmcids_file, output_dir, failure_log_dir)\u001b[0m\n\u001b[0;32m     38\u001b[0m url \u001b[38;5;241m=\u001b[39m base_url\u001b[38;5;241m.\u001b[39mformat(pmcid)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 40\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(temp_output_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m temp_file:\n",
            "File \u001b[1;32mc:\\Users\\aivan\\anaconda3\\envs\\BIOIN311\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\aivan\\anaconda3\\envs\\BIOIN311\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\aivan\\anaconda3\\envs\\BIOIN311\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
            "File \u001b[1;32mc:\\Users\\aivan\\anaconda3\\envs\\BIOIN311\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
            "File \u001b[1;32mc:\\Users\\aivan\\anaconda3\\envs\\BIOIN311\\Lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
            "File \u001b[1;32mc:\\Users\\aivan\\anaconda3\\envs\\BIOIN311\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\aivan\\anaconda3\\envs\\BIOIN311\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
            "File \u001b[1;32mc:\\Users\\aivan\\anaconda3\\envs\\BIOIN311\\Lib\\site-packages\\urllib3\\connection.py:516\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    513\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    515\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 516\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    519\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
            "File \u001b[1;32mc:\\Users\\aivan\\anaconda3\\envs\\BIOIN311\\Lib\\http\\client.py:1395\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1393\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1394\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1395\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1396\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1397\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
            "File \u001b[1;32mc:\\Users\\aivan\\anaconda3\\envs\\BIOIN311\\Lib\\http\\client.py:325\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 325\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\aivan\\anaconda3\\envs\\BIOIN311\\Lib\\http\\client.py:286\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 286\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\aivan\\anaconda3\\envs\\BIOIN311\\Lib\\socket.py:718\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    717\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 718\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    720\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\aivan\\anaconda3\\envs\\BIOIN311\\Lib\\ssl.py:1314\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1310\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1311\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1312\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1313\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
            "File \u001b[1;32mc:\\Users\\aivan\\anaconda3\\envs\\BIOIN311\\Lib\\ssl.py:1166\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1166\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1167\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1168\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "import time\n",
        "from tqdm import tqdm  # Progress bar\n",
        "\n",
        "def fetch_pmc_articles(pmcids_file, output_dir, failure_log_dir):\n",
        "    \"\"\"\n",
        "    Fetches full-text PMC articles in BioC XML format using the BioC API.\n",
        "\n",
        "    Args:\n",
        "        pmcids_file (str): Path to the file containing PMCIDs.\n",
        "        output_dir (str): Directory to save the fetched articles.\n",
        "        failure_log_dir (str): Directory to save the failure logs.\n",
        "    \"\"\"\n",
        "    # ascii instead of unicode for easier processing and compatibility\n",
        "    base_url = \"https://www.ncbi.nlm.nih.gov/research/bionlp/RESTful/pmcoa.cgi/BioC_xml/{}/ascii\"\n",
        "    \n",
        "    subset_name = os.path.splitext(os.path.basename(pmcids_file))[0]\n",
        "    failure_log = os.path.join(failure_log_dir, f\"{subset_name}_failed_fetches.txt\")\n",
        "\n",
        "    # Ensure directories exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    os.makedirs(failure_log_dir, exist_ok=True)\n",
        "\n",
        "    try:\n",
        "        with open(pmcids_file, 'r', encoding='utf-8') as file:\n",
        "            pmcids = [line.strip().split(\"\\t\")[1] for line in file if line.strip()]  # Extract only PMCIDs\n",
        "\n",
        "        # Initialize tqdm progress bar\n",
        "        for i, pmcid in enumerate(tqdm(pmcids, desc=f\"Downloading {subset_name}\", unit=\"article\")):\n",
        "            final_output_path = os.path.join(output_dir, f\"{pmcid}.xml\")\n",
        "            temp_output_path = os.path.join(output_dir, f\"{pmcid}.tmp\")\n",
        "\n",
        "            # Skip if already fetched\n",
        "            if os.path.exists(final_output_path):\n",
        "                continue\n",
        "\n",
        "            # Fetch article from BioC API\n",
        "            url = base_url.format(pmcid)\n",
        "            try:\n",
        "                response = requests.get(url, timeout=10)\n",
        "\n",
        "                if response.status_code == 200:\n",
        "                    with open(temp_output_path, 'w', encoding='utf-8') as temp_file:\n",
        "                        temp_file.write(response.text)\n",
        "                    os.rename(temp_output_path, final_output_path)  # Rename after successful fetch\n",
        "                else:\n",
        "                    with open(failure_log, 'a', encoding='utf-8') as fail_file:\n",
        "                        fail_file.write(f\"{pmcid}\\n\")\n",
        "\n",
        "            except Exception as e:\n",
        "                with open(failure_log, 'a', encoding='utf-8') as fail_file:\n",
        "                    fail_file.write(f\"{pmcid}\\n\")\n",
        "\n",
        "            time.sleep(0.5)  # Prevent overloading the API\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error processing {pmcids_file}: {e}\")\n",
        "\n",
        "def main():\n",
        "    # Directory containing subset files\n",
        "    subsets_dir = r\"C:\\Users\\aivan\\Desktop\\BIOIN 401\\GOLLM\\data\\matching_pmcids_subsets\"\n",
        "\n",
        "    # Directory to save fetched full-text articles\n",
        "    fetched_articles_subsets_dir = r\"C:\\Users\\aivan\\Desktop\\BIOIN 401\\GOLLM\\data\\fetched_full_articles_subsets\"\n",
        "\n",
        "    # Directory to save failure logs\n",
        "    failure_log_dir = r\"C:\\Users\\aivan\\Desktop\\BIOIN 401\\GOLLM\\data\\failed_full_text_fetches\"\n",
        "\n",
        "    # Iterate over each subset file and fetch articles\n",
        "    for subset_file in os.listdir(subsets_dir):\n",
        "        print(f\"\\n📂 Processing subset file: {subset_file}\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        if subset_file.endswith(\".txt\"):\n",
        "            subset_path = os.path.join(subsets_dir, subset_file)\n",
        "            subset_output_dir = os.path.join(fetched_articles_subsets_dir, os.path.splitext(subset_file)[0])\n",
        "\n",
        "            fetch_pmc_articles(subset_path, subset_output_dir, failure_log_dir)\n",
        "\n",
        "        print(f\"✅ Finished processing {subset_file}. Took {time.time() - start_time:.2f} seconds\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "BIOIN311",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
